{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%matplotlib inline\n",
    "%autoreload 2\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "import os\n",
    "import pickle\n",
    "import imp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "setGPU: Setting GPU to: 1\n"
     ]
    }
   ],
   "source": [
    "from DeepJetCore.DataCollection import DataCollection\n",
    "from DeepJetCore.compiled.c_trainDataGenerator import trainDataGenerator\n",
    "from DeepJetCore.customObjects import get_custom_objects\n",
    "\n",
    "from DeepJetCore.TrainData import TrainData\n",
    "\n",
    "from evaluation_tools import find_best_matching_truth_and_format, write_output_tree, determine_event_properties, write_event_output_tree\n",
    "from inference import make_particle_inference_dict,  collect_condensates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<datastructures.TrainData_PF.TrainData_PF_graph at 0x7f66e636c420>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# define train_data as our data collection, read from djcdc file\n",
    "train_data = DataCollection(\"../data/train_data/dataCollection.djcdc\")\n",
    "\n",
    "train_data.dataclass()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import os.path as osp\n",
    "import gc\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch_geometric.transforms as T\n",
    "\n",
    "from torch.utils.checkpoint import checkpoint\n",
    "from torch_cluster import knn_graph\n",
    "\n",
    "from torch_geometric.nn import EdgeConv, NNConv\n",
    "# from torch_geometric.nn.conv import gravnet_conv\n",
    "# from torch_geometric.nn import GravNetConv\n",
    "\n",
    "from torch_geometric.nn.pool.edge_pool import EdgePooling\n",
    "\n",
    "from torch_geometric.utils import normalized_cut\n",
    "from torch_geometric.utils import remove_self_loops\n",
    "from torch_geometric.utils.undirected import to_undirected\n",
    "from torch_geometric.nn import (graclus, max_pool, max_pool_x,\n",
    "                                global_mean_pool, global_max_pool,\n",
    "                                global_add_pool)\n",
    "\n",
    "# # something wrong with the package perhaps\n",
    "# from torch_geometric.nn import GravNetConv\n",
    "\n",
    "import sklearn.metrics\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# transform = T.Cartesian(cat=False)\n",
    "\n",
    "# from torch.optim import Optimizer\n",
    "# from torch.optim.lr_scheduler import _LRScheduler\n",
    "import math\n",
    "import sys\n",
    "\n",
    "\n",
    "from Losses import particle_condensation_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "cuda = torch.device('cuda')\n",
    "device = torch.device(\"cuda\" if cuda else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "This module contains the Estimator class implementation which provides\n",
    "code for doing the training of a PyTorch model.\n",
    "\"\"\"\n",
    "\n",
    "from __future__ import print_function\n",
    "\n",
    "from datetime import datetime\n",
    "from timeit import default_timer as timer\n",
    "\n",
    "import shutil \n",
    "import copy \n",
    "\n",
    "from torch_geometric.data import Batch      \n",
    "\n",
    "from Losses import particle_condensation_loss\n",
    "\n",
    "def logger(s):\n",
    "    \"\"\"Simple logger function which prints date/time\"\"\"\n",
    "    print(datetime.now(), s)\n",
    "\n",
    "class Estimator():\n",
    "    \"\"\"Estimator class\"\"\"\n",
    "\n",
    "    def __init__(self, model, loss_func, opt='Adam',\n",
    "                 train_losses=None, valid_losses=None,\n",
    "                 cuda=False, l1=0.):\n",
    "\n",
    "        self.model = model\n",
    "        if cuda:\n",
    "            print(\"using CUDA...\")\n",
    "            self.model.cuda()\n",
    "        self.loss_func = loss_func\n",
    "        if opt == 'Adam':\n",
    "            self.optimizer = torch.optim.Adam(self.model.parameters())\n",
    "        elif opt == 'SGD':\n",
    "            self.optimizer = torch.optim.SGD(self.model.parameters())\n",
    "\n",
    "        self.train_losses = train_losses if train_losses is not None else []\n",
    "        self.valid_losses = valid_losses if valid_losses is not None else []\n",
    "        self.l1 = l1\n",
    "\n",
    "        logger('Model: \\n%s' % model)\n",
    "        logger('Parameters: %i' %\n",
    "               sum(param.numel() for param in model.parameters()))\n",
    "\n",
    "    def l1_penalty(self, arr):\n",
    "        return torch.abs(arr).sum()\n",
    "        \n",
    "    def training_step(self, inputs, targets):\n",
    "        '''\n",
    "        Applies single optimization step on batch\n",
    "        '''\n",
    "        \n",
    "        # get dimensions... not the best way to do it but meh\n",
    "        batch_size = len(inputs[0]) # same as nevents\n",
    "        num_nodes = len(inputs[0][0]) # should be 200?\n",
    "        num_features = len(inputs[0][0][0]) # should be 6\n",
    "        num_truth_vals = len(targets[0][0][0]) # should be 11\n",
    "                        \n",
    "        # flatten batch input and target tensors from 3D to 2D by combining B and V dimmensions\n",
    "        x_tensor_flat = torch.from_numpy(np.array(inputs[0])).view(-1, num_features)\n",
    "        y_tensor_flat = torch.from_numpy(np.array(targets[0])).view(-1, num_truth_vals)\n",
    "        \n",
    "        # tensor keeping track of which batch each entry is from, after flattening\n",
    "        batch_list = [i for i in range(batch_size) for j in range(num_nodes)]\n",
    "        batch_np = np.array(batch_list)\n",
    "        batch_tensor = torch.from_numpy(batch_np)\n",
    "        \n",
    "        # make a particle inference dictionary of features and truth\n",
    "        d = make_particle_inference_dict(None, inputs[0], targets[0])\n",
    "        \n",
    "        # cartesian coordinate tensor from x_tensor_flat\n",
    "        pos_tensor = x_tensor_flat.narrow(1,1,3)\n",
    "        # pos_tensor = torch.from_numpy(d['f_pos'][:,:]) #,0:3\n",
    "\n",
    "        # put training input data into a batch structure\n",
    "        data = Batch(batch=batch_tensor, x=x_tensor_flat, edge_index=None, edge_attr=None, pos=pos_tensor)\n",
    "        \n",
    "        # modify data attributes - zero-suppressed\n",
    "        # mask based on energy - keep only sensors/cells with nonzero energy hit\n",
    "#         print(\"mask shape: \", y_tensor_flat[:,0].size())\n",
    "#         print(y_tensor_flat[:,0])\n",
    "#         mask = (y_tensor_flat[:,0] > 0.).squeeze()\n",
    "        t_mask_flat = np.reshape(d['t_mask'][:,:,0], [-1])\n",
    "#         print(\"mask shape: \", t_mask_flat.shape)\n",
    "        mask = (t_mask_flat > 0.).squeeze()\n",
    "        data.x = data.x[mask]\n",
    "        data.pos = data.pos[mask,:]\n",
    "        data.batch = data.batch[mask.squeeze()]\n",
    "        \n",
    "        y_tensor_flat = y_tensor_flat[mask]\n",
    "\n",
    "#         # target_particle_id_tensor here is analogous to MNIST digit class\n",
    "#         # get the particle ID for the detector hit with the largest energy for each event.\n",
    "#         # Note the highest energy vaue may repeat many times... we assume that after condensation,\n",
    "#         # the reconstruted particle with the greatest energy has this energy. We can say that the associated ID\n",
    "#         # is the identity of the particle (electron or photon) that initiated the event (electromagnetic shower)\n",
    "#         nevents = d['t_E'].shape[0]\n",
    "#         idxs_dominant = np.argmax(d['t_E'][:,:,0], axis=1)\n",
    "#         t_particle_id_list = []\n",
    "#         for i in range(0, nevents):\n",
    "#             idx_dominant = idxs_dominant[i]\n",
    "#             dom_ID = int(d['t_ID'][i][:,0][idx_dominant])\n",
    "#             t_particle_id_list.append(dom_ID)\n",
    "#         t_particle_id_np = np.array(t_particle_id_list)\n",
    "# #         print(t_particle_id_np)\n",
    "# #         # basically ratio of one of the classes (electron or photon)\n",
    "# #         print(np.sum(t_particle_id_np) / nevents)\n",
    "#         target_particle_id_tensor = torch.from_numpy(t_particle_id_np)\n",
    "\n",
    "        n_true_particles = np.reshape(np.max(d['t_objidx'],axis=1)+1., [d['t_objidx'].shape[0],1])\n",
    "        n_true_particles = np.reshape(n_true_particles, -1).astype(int)\n",
    "        target_num_particles_tensor = torch.from_numpy(n_true_particles)\n",
    "        \n",
    "        print(\"Applying single optimization step on batch\")\n",
    "        self.model.zero_grad()\n",
    "        self.optimizer.zero_grad()\n",
    "        \n",
    "        # call the forward step of our model to get the output tensor\n",
    "        DRN_outputs, OC_outputs = self.model(data)\n",
    "#         print(DRN_outputs.size())\n",
    "#         print(DRN_outputs)\n",
    "        \n",
    "# #         outputs_np = np.expand_dims(outputs.detach().numpy(), axis=0)\n",
    "#         outputs_np = outputs.detach().numpy()\n",
    "#         print(outputs_np)\n",
    "#         print(outputs.max(1)[1])\n",
    "        \n",
    "        # negative log likelihood loss... add the object condensation loss term to this somehow\n",
    "#         loss = F.nll_loss(outputs, target_particle_id_tensor)\n",
    "\n",
    "##        will prob have to expand this out using batch_tensor to full unmasked version, filling in the masked out parts with zeros?\n",
    "#         object_condensation_loss = torch.from_numpy(particle_condensation_loss(y_tensor_flat, OC_outputs))\n",
    "\n",
    "        # right now just random tensor as a proof of concept\n",
    "        object_condensation_loss = torch.tensor(0.0, requires_grad=True)\n",
    "        dynamic_reduction_loss = F.nll_loss(DRN_outputs, target_num_particles_tensor)\n",
    "        loss = dynamic_reduction_loss + object_condensation_loss\n",
    "        \n",
    "        print(\"DRN step loss: \", dynamic_reduction_loss)\n",
    "        print(\"OC step loss: \", object_condensation_loss)\n",
    "        print(\"total training step loss: \", loss)\n",
    "        \n",
    "        # backwards step\n",
    "        loss.backward()\n",
    "        self.optimizer.step()\n",
    "#         scheduler.batch_step()\n",
    "        \n",
    "        return loss\n",
    "\n",
    "    def save_checkpoint(self, state, is_best, filename='checkpoint.pt'):\n",
    "        directory = os.path.dirname(filename)\n",
    "        try:\n",
    "            os.stat(directory)\n",
    "        except:\n",
    "            os.mkdir(directory)\n",
    "        torch.save(state, filename)\n",
    "        if is_best:\n",
    "            bestfilename = directory+'/model_best.pt'\n",
    "            shutil.copyfile(filename, bestfilename)\n",
    "            \n",
    "    def load_checkpoint(self, filename='checkpoint.pt'):\n",
    "        checkpoint = torch.load(filename)\n",
    "        self.model.load_state_dict(checkpoint['state_dict'])\n",
    "        self.optimizer.load_state_dict(checkpoint['optimizer'])\n",
    "        self.valid_losses = checkpoint['valid_losses']\n",
    "        self.train_losses = checkpoint['train_losses']\n",
    "        \n",
    "    def load_weights(self, filename='checkpoint.pt'):\n",
    "        checkpoint = torch.load(filename)\n",
    "        old_model = copy.deepcopy(self.model)\n",
    "        old_model.load_state_dict(checkpoint['state_dict'])\n",
    "\n",
    "        def set_masked_data(new_layer, old_layer):\n",
    "            if new_layer.mask_flag:\n",
    "                new_layer.weight.data = old_layer.weight.data * old_layer.mask.data\n",
    "            else:\n",
    "                new_layer.weight.data = old_layer.weight.data\n",
    "              \n",
    "        set_masked_data(self.model.edge_network.network[0], old_model.edge_network.network[0])\n",
    "        set_masked_data(self.model.edge_network.network[2], old_model.edge_network.network[2])\n",
    "        set_masked_data(self.model.node_network.network[0], old_model.node_network.network[0])\n",
    "        set_masked_data(self.model.node_network.network[2], old_model.node_network.network[2])       \n",
    "    \n",
    "    def fit_gen(self, train_generator, n_batches=1, n_epochs=1,\n",
    "                valid_generator=None, n_valid_batches=1, verbose=0, \n",
    "                filename='checkpoint.pt'):\n",
    "        \"\"\"Runs batch training for a number of specified epochs.\"\"\"\n",
    "#         scheduler.step()\n",
    "        epoch_start = len(self.train_losses)\n",
    "        epoch_end = epoch_start + n_epochs\n",
    "        if len(self.valid_losses) > 0:\n",
    "            best_valid_loss = self.valid_losses[-1]\n",
    "        else:\n",
    "            best_valid_loss = 99999999\n",
    "        for i in range(epoch_start, epoch_end):\n",
    "            logger('Epoch %i' % i)\n",
    "            start_time = timer()\n",
    "            sum_loss = 0\n",
    "\n",
    "            # Train the model\n",
    "            print(\"training model...\")\n",
    "            self.model.train()\n",
    "            print(\"computing losses for {} batches...\".format(n_batches))\n",
    "            for j in range(n_batches):\n",
    "                batch_input, batch_target = next(train_generator)\n",
    "                batch_loss = (self.training_step(batch_input, batch_target)\n",
    "                              .cpu().data.item())\n",
    "                print(\"batch {} out of {}\".format(j+1, n_batches))\n",
    "                print(\"batch_loss: \", batch_loss)\n",
    "                sum_loss += batch_loss\n",
    "#                 print(\"sum loss: \", sum_loss)\n",
    "                if verbose > 0:\n",
    "                    logger('  Batch %i loss %f' % (j, batch_loss))\n",
    "            print(\"finished cycle\")\n",
    "            end_time = timer()\n",
    "            avg_loss = sum_loss / n_batches\n",
    "            print(\"avg_loss: \", avg_loss)\n",
    "            self.train_losses.append(avg_loss)\n",
    "            logger('  training loss %.3g time %gs' %\n",
    "                   (avg_loss, (end_time - start_time)))\n",
    "\n",
    "            # TODO: adapt this to new data scheme\n",
    "            with torch.no_grad():\n",
    "                # Evaluate the model on the validation set\n",
    "                if (valid_generator is not None) and (n_valid_batches > 0):\n",
    "                    self.model.eval()\n",
    "                    valid_loss = 0\n",
    "                    for j in range(n_valid_batches):\n",
    "                        valid_input, valid_target = next(valid_generator)\n",
    "                        valid_loss += (self.loss_func(self.model(valid_input), valid_target)\n",
    "                                       .cpu().data.item())\n",
    "                    valid_loss = valid_loss / n_valid_batches\n",
    "                    self.valid_losses.append(valid_loss)\n",
    "                    logger('  validate loss %.3g' % valid_loss)\n",
    "                \n",
    "                    #Save model checkpoint - modified\n",
    "                    logger(' save checkpoint') \n",
    "                    is_best = valid_loss < best_valid_loss\n",
    "                    best_valid_loss = min(valid_loss, best_valid_loss)\n",
    "                    self.save_checkpoint({\n",
    "                        'epoch': i + 1,\n",
    "                        'state_dict': self.model.state_dict(),\n",
    "                        'best_valid_loss': best_valid_loss,\n",
    "                        'valid_losses': self.valid_losses,\n",
    "                        'train_losses': self.train_losses,\n",
    "                        'optimizer' : self.optimizer.state_dict(),\n",
    "                    }, is_best, filename=filename)\n",
    "\n",
    "    def predict(self, generator, n_batches, concat=True):\n",
    "        with torch.no_grad():  \n",
    "            self.model.eval()\n",
    "            outputs = []\n",
    "            for j in range(n_batches):\n",
    "                test_input, test_target = next(generator)\n",
    "                outputs.append(self.model(test_input))\n",
    "            if concat:\n",
    "                outputs = torch.cat(outputs)\n",
    "            return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from GravNet import GravNetConv\n",
    "from old_GravNet import GravNet\n",
    "\n",
    "transform = T.Cartesian(cat=False)\n",
    "\n",
    "def normalized_cut_2d(edge_index, pos):\n",
    "    row, col = edge_index\n",
    "    edge_attr = torch.norm(pos[row] - pos[col], p=2, dim=1)\n",
    "    return normalized_cut(edge_index, edge_attr, num_nodes=pos.size(0))\n",
    "\n",
    "class DRNOC(nn.Module):\n",
    "#     This model iteratively contracts nearest neighbour graphs \n",
    "#     until there is one output node.\n",
    "#     The latent space trained to group useful features at each level\n",
    "#     of aggregration.\n",
    "#     This allows single quantities to be regressed from complex point counts\n",
    "#     in a location and orientation invariant way.\n",
    "#     One encoding layer is used to abstract away the input features.\n",
    "    def __init__(self, input_dim=5, hidden_dim=64, output_dim=1, k=16, aggr='add',\n",
    "                 norm=torch.tensor([1.,1.,1.,1.])):\n",
    "        super(DRNOC, self).__init__()\n",
    "\n",
    "        self.datanorm = nn.Parameter(norm)\n",
    "        self.input_dim = input_dim\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.output_dim = output_dim\n",
    "        self.k = k\n",
    "        start_width = 2 * hidden_dim\n",
    "        middle_width = 3 * hidden_dim // 2\n",
    "\n",
    "        self.inputnet =  nn.Sequential(\n",
    "            nn.Linear(input_dim, hidden_dim//2),            \n",
    "            nn.ELU(),\n",
    "            nn.Linear(hidden_dim//2, hidden_dim),\n",
    "            nn.ELU(),\n",
    "            nn.Linear(hidden_dim, hidden_dim),\n",
    "            nn.ELU(),\n",
    "        )        \n",
    "        convnn1 = nn.Sequential(nn.Linear(start_width, middle_width),\n",
    "                                nn.ELU(),\n",
    "                                nn.Linear(middle_width, hidden_dim),                                             \n",
    "                                nn.ELU()\n",
    "                                )\n",
    "        convnn2 = nn.Sequential(nn.Linear(start_width, middle_width),\n",
    "                                nn.ELU(),\n",
    "                                nn.Linear(middle_width, hidden_dim),                                             \n",
    "                                nn.ELU()\n",
    "                                )                \n",
    "        \n",
    "        # The edge convolutional operator from the “Dynamic Graph CNN for Learning on Point Clouds” paper\n",
    "        self.edgeconv1 = EdgeConv(nn=convnn1, aggr=aggr)\n",
    "        self.edgeconv2 = EdgeConv(nn=convnn2, aggr=aggr)\n",
    "        \n",
    "        self.output = nn.Sequential(nn.Linear(hidden_dim, hidden_dim),\n",
    "                                    nn.ELU(),\n",
    "                                    nn.Linear(hidden_dim, hidden_dim//2),\n",
    "                                    nn.ELU(),                                    \n",
    "                                    nn.Linear(hidden_dim//2, output_dim))\n",
    "        \n",
    "        \n",
    "    def forward(self, data):\n",
    "        \n",
    "        # object condensation step\n",
    "        print(\"starting object condensation step...\")\n",
    "        # define output predictions format\n",
    "        def output_block(x,ids,energy_raw):\n",
    "            p_beta    = nn.Sigmoid()(nn.Linear(x.size()[-1], 1)(x))\n",
    "\n",
    "            p_tpos    = 10. * nn.Linear(x.size()[-1], 2)(x)\n",
    "            p_ID      = nn.Softmax()(nn.Linear(x.size()[-1], 2)(x))\n",
    "\n",
    "            p_E       = (nn.Linear(x.size()[-1], 1)(x))\n",
    "            p_ccoords = 10. * nn.Linear(x.size()[-1], 2)(x)\n",
    "\n",
    "            predictions=torch.cat([p_beta ,\n",
    "                                       p_E    ,\n",
    "                                       p_tpos   ,\n",
    "                                       p_ID     ,\n",
    "                                       p_ccoords,\n",
    "                                       ids,\n",
    "                                       energy_raw], dim=1)\n",
    "\n",
    "            print('predictions',predictions.size())\n",
    "            return predictions\n",
    "\n",
    "        def OC_minimodel(x):\n",
    "            # select features from keras layer x from index 0 to index 3\n",
    "            # feature energy and position: f_E and f_pos\n",
    "            energy_raw = x[...,0:3]\n",
    "            ids = x[...,5:6]\n",
    "            print(energy_raw.size())\n",
    "            # re-center and re-scale\n",
    "            x = nn.BatchNorm1d(x.size()[-1], momentum=0.6)(x)\n",
    "            feat=[x]\n",
    "\n",
    "            for i in range(6):\n",
    "                #add global exchange and another dense here\n",
    "                \n",
    "# #                 mean = tf.reduce_mean(x, axis=1, keepdims=True)\n",
    "# #                 mean = tf.tile(mean, [1, self.num_vertices, 1])\n",
    "# #                 return tf.concat([x, mean], axis=-1)\n",
    "#                 x = GlobalExchange()(x)\n",
    "                x = nn.ELU(alpha=0.6)(nn.Linear(x.size()[-1], 64)(x))\n",
    "                x = nn.ELU(alpha=0.6)(nn.Linear(64, 64)(x))\n",
    "                x = nn.BatchNorm1d(64, momentum=0.6)(x)\n",
    "                x = nn.ELU(alpha=0.6)(nn.Linear(x.size()[-1], 64)(x))\n",
    "\n",
    "#                 x = GravNetConv(in_channels=x.size()[-1], \n",
    "#                          out_channels=128, \n",
    "#                          space_dimensions=4, \n",
    "#                          propagate_dimensions=64, k=self.k)(x)\n",
    "\n",
    "#                 x = GravNet(n_blocks=4, final_dim=128, n_clusters=2,\n",
    "#                             input_dim=64, out_dim=128, spatial_dim=4, dense_dim=64, n_neighbors=10)(x)\n",
    "\n",
    "#                 x = GravNet(input_dim=64, out_dim=128, spatial_dim=4, n_neighbors=10)(x)\n",
    "    \n",
    "                x = nn.BatchNorm1d(x.size()[-1], momentum=0.6)(x)\n",
    "                feat.append(nn.ELU(alpha=0.6)(nn.Linear(x.size()[-1], 32)(x)))\n",
    "            \n",
    "#             # without GravNet enforcing 4 spatial dimensions, feat is ragged and we cannot concatenate\n",
    "#             x = torch.cat(feat)\n",
    "            x = nn.ELU(alpha=0.6)(nn.Linear(x.size()[-1], 64)(x))\n",
    "            preds = output_block(x, ids, energy_raw)\n",
    "            return preds\n",
    "\n",
    "        preds = OC_minimodel(data.x)\n",
    "        print(\"alright buckaroo\")\n",
    "        print(preds.size())\n",
    "#         print(preds)\n",
    "        \n",
    "        \n",
    "        # dynamic reduction step\n",
    "        print(\"startin dynamic reduction step...\")\n",
    "#         data.x = self.datanorm * data.x\n",
    "\n",
    "        data.x = preds\n",
    "        data.x = nn.BatchNorm1d(data.x.size()[-1], momentum=0.6)(data.x)\n",
    "        data.x = self.inputnet(data.x)\n",
    "\n",
    "        data.edge_index = to_undirected(knn_graph(data.x, self.k, data.batch, loop=False, flow=self.edgeconv1.flow))\n",
    "        data.x = self.edgeconv1(data.x, data.edge_index)\n",
    "        \n",
    "        weight = normalized_cut_2d(data.edge_index, data.x)\n",
    "        \n",
    "        # replace with condensation-based clustering ?\n",
    "        print(\"clustering to dimension: \", data.x.size(0))\n",
    "        cluster = graclus(data.edge_index, weight, data.x.size(0))\n",
    "\n",
    "        data.edge_attr = None\n",
    "        data = max_pool(cluster, data)\n",
    "        \n",
    "        data.edge_index = to_undirected(knn_graph(data.x, self.k, data.batch, loop=False, flow=self.edgeconv2.flow))\n",
    "        data.x = self.edgeconv2(data.x, data.edge_index)\n",
    "        \n",
    "        weight = normalized_cut_2d(data.edge_index, data.x)\n",
    "        \n",
    "        # replace with condensation-based clustering ?\n",
    "        print(\"clustering to dimension: \", data.x.size(0))\n",
    "        cluster = graclus(data.edge_index, weight, data.x.size(0))\n",
    "        \n",
    "        x, batch = max_pool_x(cluster, data.x, data.batch)\n",
    "#         # it seems like the batch tensor (each batch corresponds to an event) at this point associates each\n",
    "#         # point in x with the event it is from. It looks almost exactly like the condensation eventparticles\n",
    "#         print(batch.size())\n",
    "#         print(batch[0:40])\n",
    "        x = global_max_pool(x, batch)\n",
    "                \n",
    "        x = self.output(x).squeeze(-1)\n",
    "        return x, preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "features -> 6\n",
      "classes -> 9\n",
      "hidden_dim = 20\n",
      "Model: \n",
      "Net(\n",
      "  (drnoc): DRNOC(\n",
      "    (inputnet): Sequential(\n",
      "      (0): Linear(in_features=12, out_features=10, bias=True)\n",
      "      (1): ELU(alpha=1.0)\n",
      "      (2): Linear(in_features=10, out_features=20, bias=True)\n",
      "      (3): ELU(alpha=1.0)\n",
      "      (4): Linear(in_features=20, out_features=20, bias=True)\n",
      "      (5): ELU(alpha=1.0)\n",
      "    )\n",
      "    (edgeconv1): EdgeConv(nn=Sequential(\n",
      "      (0): Linear(in_features=40, out_features=30, bias=True)\n",
      "      (1): ELU(alpha=1.0)\n",
      "      (2): Linear(in_features=30, out_features=20, bias=True)\n",
      "      (3): ELU(alpha=1.0)\n",
      "    ))\n",
      "    (edgeconv2): EdgeConv(nn=Sequential(\n",
      "      (0): Linear(in_features=40, out_features=30, bias=True)\n",
      "      (1): ELU(alpha=1.0)\n",
      "      (2): Linear(in_features=30, out_features=20, bias=True)\n",
      "      (3): ELU(alpha=1.0)\n",
      "    ))\n",
      "    (output): Sequential(\n",
      "      (0): Linear(in_features=20, out_features=20, bias=True)\n",
      "      (1): ELU(alpha=1.0)\n",
      "      (2): Linear(in_features=20, out_features=10, bias=True)\n",
      "      (3): ELU(alpha=1.0)\n",
      "      (4): Linear(in_features=10, out_features=9, bias=True)\n",
      "    )\n",
      "  )\n",
      ")\n",
      "Parameters: 5205\n",
      "2020-06-29 00:26:07.904591 Model: \n",
      "Net(\n",
      "  (drnoc): DRNOC(\n",
      "    (inputnet): Sequential(\n",
      "      (0): Linear(in_features=12, out_features=10, bias=True)\n",
      "      (1): ELU(alpha=1.0)\n",
      "      (2): Linear(in_features=10, out_features=20, bias=True)\n",
      "      (3): ELU(alpha=1.0)\n",
      "      (4): Linear(in_features=20, out_features=20, bias=True)\n",
      "      (5): ELU(alpha=1.0)\n",
      "    )\n",
      "    (edgeconv1): EdgeConv(nn=Sequential(\n",
      "      (0): Linear(in_features=40, out_features=30, bias=True)\n",
      "      (1): ELU(alpha=1.0)\n",
      "      (2): Linear(in_features=30, out_features=20, bias=True)\n",
      "      (3): ELU(alpha=1.0)\n",
      "    ))\n",
      "    (edgeconv2): EdgeConv(nn=Sequential(\n",
      "      (0): Linear(in_features=40, out_features=30, bias=True)\n",
      "      (1): ELU(alpha=1.0)\n",
      "      (2): Linear(in_features=30, out_features=20, bias=True)\n",
      "      (3): ELU(alpha=1.0)\n",
      "    ))\n",
      "    (output): Sequential(\n",
      "      (0): Linear(in_features=20, out_features=20, bias=True)\n",
      "      (1): ELU(alpha=1.0)\n",
      "      (2): Linear(in_features=20, out_features=10, bias=True)\n",
      "      (3): ELU(alpha=1.0)\n",
      "      (4): Linear(in_features=10, out_features=9, bias=True)\n",
      "    )\n",
      "  )\n",
      ")\n",
      "2020-06-29 00:26:07.904734 Parameters: 5205\n",
      "2020-06-29 00:26:07.904846 Epoch 0\n",
      "training model...\n",
      "computing losses for 2992 batches...\n",
      "Applying single optimization step on batch\n",
      "starting object condensation step...\n",
      "torch.Size([7837, 3])\n",
      "predictions torch.Size([7837, 12])\n",
      "alright buckaroo\n",
      "torch.Size([7837, 12])\n",
      "startin dynamic reduction step...\n",
      "clustering to dimension:  7837\n",
      "clustering to dimension:  4116\n",
      "DRN step loss:  tensor(2.2724, grad_fn=<NllLossBackward>)\n",
      "OC step loss:  tensor(0., requires_grad=True)\n",
      "total training step loss:  tensor(2.2724, grad_fn=<AddBackward0>)\n",
      "batch 1 out of 2992\n",
      "batch_loss:  2.272395372390747\n",
      "Applying single optimization step on batch\n",
      "starting object condensation step...\n",
      "torch.Size([7715, 3])\n",
      "predictions torch.Size([7715, 12])\n",
      "alright buckaroo\n",
      "torch.Size([7715, 12])\n",
      "startin dynamic reduction step...\n",
      "clustering to dimension:  7715\n",
      "clustering to dimension:  4040\n",
      "DRN step loss:  tensor(2.2695, grad_fn=<NllLossBackward>)\n",
      "OC step loss:  tensor(0., requires_grad=True)\n",
      "total training step loss:  tensor(2.2695, grad_fn=<AddBackward0>)\n",
      "batch 2 out of 2992\n",
      "batch_loss:  2.2695016860961914\n",
      "Applying single optimization step on batch\n",
      "starting object condensation step...\n",
      "torch.Size([7505, 3])\n",
      "predictions torch.Size([7505, 12])\n",
      "alright buckaroo\n",
      "torch.Size([7505, 12])\n",
      "startin dynamic reduction step...\n",
      "clustering to dimension:  7505\n",
      "clustering to dimension:  3939\n",
      "DRN step loss:  tensor(2.2480, grad_fn=<NllLossBackward>)\n",
      "OC step loss:  tensor(0., requires_grad=True)\n",
      "total training step loss:  tensor(2.2480, grad_fn=<AddBackward0>)\n",
      "batch 3 out of 2992\n",
      "batch_loss:  2.2479915618896484\n",
      "Applying single optimization step on batch\n",
      "starting object condensation step...\n",
      "torch.Size([7602, 3])\n",
      "predictions torch.Size([7602, 12])\n",
      "alright buckaroo\n",
      "torch.Size([7602, 12])\n",
      "startin dynamic reduction step...\n",
      "clustering to dimension:  7602\n",
      "clustering to dimension:  3991\n",
      "DRN step loss:  tensor(2.2332, grad_fn=<NllLossBackward>)\n",
      "OC step loss:  tensor(0., requires_grad=True)\n",
      "total training step loss:  tensor(2.2332, grad_fn=<AddBackward0>)\n",
      "batch 4 out of 2992\n",
      "batch_loss:  2.2332379817962646\n",
      "Applying single optimization step on batch\n",
      "starting object condensation step...\n",
      "torch.Size([7712, 3])\n",
      "predictions torch.Size([7712, 12])\n",
      "alright buckaroo\n",
      "torch.Size([7712, 12])\n",
      "startin dynamic reduction step...\n",
      "clustering to dimension:  7712\n",
      "clustering to dimension:  4044\n",
      "DRN step loss:  tensor(2.1900, grad_fn=<NllLossBackward>)\n",
      "OC step loss:  tensor(0., requires_grad=True)\n",
      "total training step loss:  tensor(2.1900, grad_fn=<AddBackward0>)\n",
      "batch 5 out of 2992\n",
      "batch_loss:  2.190004587173462\n",
      "Applying single optimization step on batch\n",
      "starting object condensation step...\n",
      "torch.Size([7851, 3])\n",
      "predictions torch.Size([7851, 12])\n",
      "alright buckaroo\n",
      "torch.Size([7851, 12])\n",
      "startin dynamic reduction step...\n",
      "clustering to dimension:  7851\n",
      "clustering to dimension:  4116\n",
      "DRN step loss:  tensor(2.1725, grad_fn=<NllLossBackward>)\n",
      "OC step loss:  tensor(0., requires_grad=True)\n",
      "total training step loss:  tensor(2.1725, grad_fn=<AddBackward0>)\n",
      "batch 6 out of 2992\n",
      "batch_loss:  2.1724541187286377\n",
      "Applying single optimization step on batch\n",
      "starting object condensation step...\n",
      "torch.Size([7576, 3])\n",
      "predictions torch.Size([7576, 12])\n",
      "alright buckaroo\n",
      "torch.Size([7576, 12])\n",
      "startin dynamic reduction step...\n",
      "clustering to dimension:  7576\n",
      "clustering to dimension:  3977\n",
      "DRN step loss:  tensor(2.1695, grad_fn=<NllLossBackward>)\n",
      "OC step loss:  tensor(0., requires_grad=True)\n",
      "total training step loss:  tensor(2.1695, grad_fn=<AddBackward0>)\n",
      "batch 7 out of 2992\n",
      "batch_loss:  2.169517993927002\n",
      "Applying single optimization step on batch\n",
      "starting object condensation step...\n",
      "torch.Size([7545, 3])\n",
      "predictions torch.Size([7545, 12])\n",
      "alright buckaroo\n",
      "torch.Size([7545, 12])\n",
      "startin dynamic reduction step...\n",
      "clustering to dimension:  7545\n",
      "clustering to dimension:  3956\n",
      "DRN step loss:  tensor(2.1633, grad_fn=<NllLossBackward>)\n",
      "OC step loss:  tensor(0., requires_grad=True)\n",
      "total training step loss:  tensor(2.1633, grad_fn=<AddBackward0>)\n",
      "batch 8 out of 2992\n",
      "batch_loss:  2.1633381843566895\n",
      "Applying single optimization step on batch\n",
      "starting object condensation step...\n",
      "torch.Size([7608, 3])\n",
      "predictions torch.Size([7608, 12])\n",
      "alright buckaroo\n",
      "torch.Size([7608, 12])\n",
      "startin dynamic reduction step...\n",
      "clustering to dimension:  7608\n",
      "clustering to dimension:  3991\n",
      "DRN step loss:  tensor(2.1485, grad_fn=<NllLossBackward>)\n",
      "OC step loss:  tensor(0., requires_grad=True)\n",
      "total training step loss:  tensor(2.1485, grad_fn=<AddBackward0>)\n",
      "batch 9 out of 2992\n",
      "batch_loss:  2.14850115776062\n",
      "Applying single optimization step on batch\n",
      "starting object condensation step...\n",
      "torch.Size([7775, 3])\n",
      "predictions torch.Size([7775, 12])\n",
      "alright buckaroo\n",
      "torch.Size([7775, 12])\n",
      "startin dynamic reduction step...\n",
      "clustering to dimension:  7775\n",
      "clustering to dimension:  4084\n",
      "DRN step loss:  tensor(2.1228, grad_fn=<NllLossBackward>)\n",
      "OC step loss:  tensor(0., requires_grad=True)\n",
      "total training step loss:  tensor(2.1228, grad_fn=<AddBackward0>)\n",
      "batch 10 out of 2992\n",
      "batch_loss:  2.1228129863739014\n",
      "Applying single optimization step on batch\n",
      "starting object condensation step...\n",
      "torch.Size([7681, 3])\n",
      "predictions torch.Size([7681, 12])\n",
      "alright buckaroo\n",
      "torch.Size([7681, 12])\n",
      "startin dynamic reduction step...\n",
      "clustering to dimension:  7681\n",
      "clustering to dimension:  4034\n",
      "DRN step loss:  tensor(2.1165, grad_fn=<NllLossBackward>)\n",
      "OC step loss:  tensor(0., requires_grad=True)\n",
      "total training step loss:  tensor(2.1165, grad_fn=<AddBackward0>)\n",
      "batch 11 out of 2992\n",
      "batch_loss:  2.116487741470337\n",
      "Applying single optimization step on batch\n",
      "starting object condensation step...\n",
      "torch.Size([7391, 3])\n",
      "predictions torch.Size([7391, 12])\n",
      "alright buckaroo\n",
      "torch.Size([7391, 12])\n",
      "startin dynamic reduction step...\n",
      "clustering to dimension:  7391\n",
      "clustering to dimension:  3880\n",
      "DRN step loss:  tensor(2.1127, grad_fn=<NllLossBackward>)\n",
      "OC step loss:  tensor(0., requires_grad=True)\n",
      "total training step loss:  tensor(2.1127, grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch 12 out of 2992\n",
      "batch_loss:  2.1126961708068848\n",
      "Applying single optimization step on batch\n",
      "starting object condensation step...\n",
      "torch.Size([7676, 3])\n",
      "predictions torch.Size([7676, 12])\n",
      "alright buckaroo\n",
      "torch.Size([7676, 12])\n",
      "startin dynamic reduction step...\n",
      "clustering to dimension:  7676\n",
      "clustering to dimension:  4037\n",
      "DRN step loss:  tensor(2.1066, grad_fn=<NllLossBackward>)\n",
      "OC step loss:  tensor(0., requires_grad=True)\n",
      "total training step loss:  tensor(2.1066, grad_fn=<AddBackward0>)\n",
      "batch 13 out of 2992\n",
      "batch_loss:  2.106593370437622\n",
      "Applying single optimization step on batch\n",
      "starting object condensation step...\n",
      "torch.Size([7735, 3])\n",
      "predictions torch.Size([7735, 12])\n",
      "alright buckaroo\n",
      "torch.Size([7735, 12])\n",
      "startin dynamic reduction step...\n",
      "clustering to dimension:  7735\n",
      "clustering to dimension:  4072\n",
      "DRN step loss:  tensor(2.0728, grad_fn=<NllLossBackward>)\n",
      "OC step loss:  tensor(0., requires_grad=True)\n",
      "total training step loss:  tensor(2.0728, grad_fn=<AddBackward0>)\n",
      "batch 14 out of 2992\n",
      "batch_loss:  2.0728490352630615\n",
      "Applying single optimization step on batch\n",
      "starting object condensation step...\n",
      "torch.Size([7915, 3])\n",
      "predictions torch.Size([7915, 12])\n",
      "alright buckaroo\n",
      "torch.Size([7915, 12])\n",
      "startin dynamic reduction step...\n",
      "clustering to dimension:  7915\n",
      "clustering to dimension:  4151\n",
      "DRN step loss:  tensor(2.0498, grad_fn=<NllLossBackward>)\n",
      "OC step loss:  tensor(0., requires_grad=True)\n",
      "total training step loss:  tensor(2.0498, grad_fn=<AddBackward0>)\n",
      "batch 15 out of 2992\n",
      "batch_loss:  2.049783945083618\n",
      "Applying single optimization step on batch\n",
      "starting object condensation step...\n",
      "torch.Size([7533, 3])\n",
      "predictions torch.Size([7533, 12])\n",
      "alright buckaroo\n",
      "torch.Size([7533, 12])\n",
      "startin dynamic reduction step...\n",
      "clustering to dimension:  7533\n",
      "clustering to dimension:  3965\n",
      "DRN step loss:  tensor(2.0657, grad_fn=<NllLossBackward>)\n",
      "OC step loss:  tensor(0., requires_grad=True)\n",
      "total training step loss:  tensor(2.0657, grad_fn=<AddBackward0>)\n",
      "batch 16 out of 2992\n",
      "batch_loss:  2.065660238265991\n",
      "Applying single optimization step on batch\n",
      "starting object condensation step...\n",
      "torch.Size([7511, 3])\n",
      "predictions torch.Size([7511, 12])\n",
      "alright buckaroo\n",
      "torch.Size([7511, 12])\n",
      "startin dynamic reduction step...\n",
      "clustering to dimension:  7511\n",
      "clustering to dimension:  3939\n",
      "DRN step loss:  tensor(2.0483, grad_fn=<NllLossBackward>)\n",
      "OC step loss:  tensor(0., requires_grad=True)\n",
      "total training step loss:  tensor(2.0483, grad_fn=<AddBackward0>)\n",
      "batch 17 out of 2992\n",
      "batch_loss:  2.0482876300811768\n",
      "Applying single optimization step on batch\n",
      "starting object condensation step...\n",
      "torch.Size([7703, 3])\n",
      "predictions torch.Size([7703, 12])\n",
      "alright buckaroo\n",
      "torch.Size([7703, 12])\n",
      "startin dynamic reduction step...\n",
      "clustering to dimension:  7703\n",
      "clustering to dimension:  4040\n",
      "DRN step loss:  tensor(2.0386, grad_fn=<NllLossBackward>)\n",
      "OC step loss:  tensor(0., requires_grad=True)\n",
      "total training step loss:  tensor(2.0386, grad_fn=<AddBackward0>)\n",
      "batch 18 out of 2992\n",
      "batch_loss:  2.038574695587158\n",
      "Applying single optimization step on batch\n",
      "starting object condensation step...\n",
      "torch.Size([7741, 3])\n",
      "predictions torch.Size([7741, 12])\n",
      "alright buckaroo\n",
      "torch.Size([7741, 12])\n",
      "startin dynamic reduction step...\n",
      "clustering to dimension:  7741\n",
      "clustering to dimension:  4064\n",
      "DRN step loss:  tensor(2.0085, grad_fn=<NllLossBackward>)\n",
      "OC step loss:  tensor(0., requires_grad=True)\n",
      "total training step loss:  tensor(2.0085, grad_fn=<AddBackward0>)\n",
      "batch 19 out of 2992\n",
      "batch_loss:  2.0084712505340576\n",
      "Applying single optimization step on batch\n",
      "starting object condensation step...\n",
      "torch.Size([7682, 3])\n",
      "predictions torch.Size([7682, 12])\n",
      "alright buckaroo\n",
      "torch.Size([7682, 12])\n",
      "startin dynamic reduction step...\n",
      "clustering to dimension:  7682\n",
      "clustering to dimension:  4030\n",
      "DRN step loss:  tensor(1.9959, grad_fn=<NllLossBackward>)\n",
      "OC step loss:  tensor(0., requires_grad=True)\n",
      "total training step loss:  tensor(1.9959, grad_fn=<AddBackward0>)\n",
      "batch 20 out of 2992\n",
      "batch_loss:  1.995914340019226\n",
      "Applying single optimization step on batch\n",
      "starting object condensation step...\n",
      "torch.Size([7417, 3])\n",
      "predictions torch.Size([7417, 12])\n",
      "alright buckaroo\n",
      "torch.Size([7417, 12])\n",
      "startin dynamic reduction step...\n",
      "clustering to dimension:  7417\n",
      "clustering to dimension:  3893\n",
      "DRN step loss:  tensor(2.0170, grad_fn=<NllLossBackward>)\n",
      "OC step loss:  tensor(0., requires_grad=True)\n",
      "total training step loss:  tensor(2.0170, grad_fn=<AddBackward0>)\n",
      "batch 21 out of 2992\n",
      "batch_loss:  2.0169625282287598\n",
      "Applying single optimization step on batch\n",
      "starting object condensation step...\n",
      "torch.Size([7632, 3])\n",
      "predictions torch.Size([7632, 12])\n",
      "alright buckaroo\n",
      "torch.Size([7632, 12])\n",
      "startin dynamic reduction step...\n",
      "clustering to dimension:  7632\n",
      "clustering to dimension:  4022\n",
      "DRN step loss:  tensor(1.9847, grad_fn=<NllLossBackward>)\n",
      "OC step loss:  tensor(0., requires_grad=True)\n",
      "total training step loss:  tensor(1.9847, grad_fn=<AddBackward0>)\n",
      "batch 22 out of 2992\n",
      "batch_loss:  1.9846773147583008\n",
      "Applying single optimization step on batch\n",
      "starting object condensation step...\n",
      "torch.Size([7757, 3])\n",
      "predictions torch.Size([7757, 12])\n",
      "alright buckaroo\n",
      "torch.Size([7757, 12])\n",
      "startin dynamic reduction step...\n",
      "clustering to dimension:  7757\n",
      "clustering to dimension:  4072\n",
      "DRN step loss:  tensor(1.9606, grad_fn=<NllLossBackward>)\n",
      "OC step loss:  tensor(0., requires_grad=True)\n",
      "total training step loss:  tensor(1.9606, grad_fn=<AddBackward0>)\n",
      "batch 23 out of 2992\n",
      "batch_loss:  1.9606283903121948\n",
      "Applying single optimization step on batch\n",
      "starting object condensation step...\n",
      "torch.Size([7862, 3])\n",
      "predictions torch.Size([7862, 12])\n",
      "alright buckaroo\n",
      "torch.Size([7862, 12])\n",
      "startin dynamic reduction step...\n",
      "clustering to dimension:  7862\n",
      "clustering to dimension:  4116\n",
      "DRN step loss:  tensor(1.9477, grad_fn=<NllLossBackward>)\n",
      "OC step loss:  tensor(0., requires_grad=True)\n",
      "total training step loss:  tensor(1.9477, grad_fn=<AddBackward0>)\n",
      "batch 24 out of 2992\n",
      "batch_loss:  1.947727918624878\n",
      "Applying single optimization step on batch\n",
      "starting object condensation step...\n",
      "torch.Size([7557, 3])\n",
      "predictions torch.Size([7557, 12])\n",
      "alright buckaroo\n",
      "torch.Size([7557, 12])\n",
      "startin dynamic reduction step...\n",
      "clustering to dimension:  7557\n",
      "clustering to dimension:  3969\n",
      "DRN step loss:  tensor(1.9540, grad_fn=<NllLossBackward>)\n",
      "OC step loss:  tensor(0., requires_grad=True)\n",
      "total training step loss:  tensor(1.9540, grad_fn=<AddBackward0>)\n",
      "batch 25 out of 2992\n",
      "batch_loss:  1.954017996788025\n",
      "Applying single optimization step on batch\n",
      "starting object condensation step...\n",
      "torch.Size([7537, 3])\n",
      "predictions torch.Size([7537, 12])\n",
      "alright buckaroo\n",
      "torch.Size([7537, 12])\n",
      "startin dynamic reduction step...\n",
      "clustering to dimension:  7537\n",
      "clustering to dimension:  3975\n",
      "DRN step loss:  tensor(1.9439, grad_fn=<NllLossBackward>)\n",
      "OC step loss:  tensor(0., requires_grad=True)\n",
      "total training step loss:  tensor(1.9439, grad_fn=<AddBackward0>)\n",
      "batch 26 out of 2992\n",
      "batch_loss:  1.943877100944519\n",
      "Applying single optimization step on batch\n",
      "starting object condensation step...\n",
      "torch.Size([7576, 3])\n",
      "predictions torch.Size([7576, 12])\n",
      "alright buckaroo\n",
      "torch.Size([7576, 12])\n",
      "startin dynamic reduction step...\n",
      "clustering to dimension:  7576\n",
      "clustering to dimension:  3954\n",
      "DRN step loss:  tensor(1.9221, grad_fn=<NllLossBackward>)\n",
      "OC step loss:  tensor(0., requires_grad=True)\n",
      "total training step loss:  tensor(1.9221, grad_fn=<AddBackward0>)\n",
      "batch 27 out of 2992\n",
      "batch_loss:  1.9221234321594238\n",
      "Applying single optimization step on batch\n",
      "starting object condensation step...\n",
      "torch.Size([7833, 3])\n",
      "predictions torch.Size([7833, 12])\n",
      "alright buckaroo\n",
      "torch.Size([7833, 12])\n",
      "startin dynamic reduction step...\n",
      "clustering to dimension:  7833\n",
      "clustering to dimension:  4112\n",
      "DRN step loss:  tensor(1.8872, grad_fn=<NllLossBackward>)\n",
      "OC step loss:  tensor(0., requires_grad=True)\n",
      "total training step loss:  tensor(1.8872, grad_fn=<AddBackward0>)\n",
      "batch 28 out of 2992\n",
      "batch_loss:  1.8871941566467285\n",
      "Applying single optimization step on batch\n",
      "starting object condensation step...\n",
      "torch.Size([7725, 3])\n",
      "predictions torch.Size([7725, 12])\n",
      "alright buckaroo\n",
      "torch.Size([7725, 12])\n",
      "startin dynamic reduction step...\n",
      "clustering to dimension:  7725\n",
      "clustering to dimension:  4054\n",
      "DRN step loss:  tensor(1.9065, grad_fn=<NllLossBackward>)\n",
      "OC step loss:  tensor(0., requires_grad=True)\n",
      "total training step loss:  tensor(1.9065, grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch 29 out of 2992\n",
      "batch_loss:  1.9064692258834839\n",
      "Applying single optimization step on batch\n",
      "starting object condensation step...\n",
      "torch.Size([7499, 3])\n",
      "predictions torch.Size([7499, 12])\n",
      "alright buckaroo\n",
      "torch.Size([7499, 12])\n",
      "startin dynamic reduction step...\n",
      "clustering to dimension:  7499\n",
      "clustering to dimension:  3930\n",
      "DRN step loss:  tensor(1.8867, grad_fn=<NllLossBackward>)\n",
      "OC step loss:  tensor(0., requires_grad=True)\n",
      "total training step loss:  tensor(1.8867, grad_fn=<AddBackward0>)\n",
      "batch 30 out of 2992\n",
      "batch_loss:  1.8866533041000366\n",
      "Applying single optimization step on batch\n",
      "starting object condensation step...\n",
      "torch.Size([7573, 3])\n",
      "predictions torch.Size([7573, 12])\n",
      "alright buckaroo\n",
      "torch.Size([7573, 12])\n",
      "startin dynamic reduction step...\n",
      "clustering to dimension:  7573\n",
      "clustering to dimension:  3989\n",
      "DRN step loss:  tensor(1.9079, grad_fn=<NllLossBackward>)\n",
      "OC step loss:  tensor(0., requires_grad=True)\n",
      "total training step loss:  tensor(1.9079, grad_fn=<AddBackward0>)\n",
      "batch 31 out of 2992\n",
      "batch_loss:  1.9078696966171265\n",
      "Applying single optimization step on batch\n",
      "starting object condensation step...\n",
      "torch.Size([7761, 3])\n",
      "predictions torch.Size([7761, 12])\n",
      "alright buckaroo\n",
      "torch.Size([7761, 12])\n",
      "startin dynamic reduction step...\n",
      "clustering to dimension:  7761\n",
      "clustering to dimension:  4072\n",
      "DRN step loss:  tensor(1.8519, grad_fn=<NllLossBackward>)\n",
      "OC step loss:  tensor(0., requires_grad=True)\n",
      "total training step loss:  tensor(1.8519, grad_fn=<AddBackward0>)\n",
      "batch 32 out of 2992\n",
      "batch_loss:  1.8519257307052612\n",
      "Applying single optimization step on batch\n",
      "starting object condensation step...\n",
      "torch.Size([7813, 3])\n",
      "predictions torch.Size([7813, 12])\n",
      "alright buckaroo\n",
      "torch.Size([7813, 12])\n",
      "startin dynamic reduction step...\n",
      "clustering to dimension:  7813\n",
      "clustering to dimension:  4086\n",
      "DRN step loss:  tensor(1.8040, grad_fn=<NllLossBackward>)\n",
      "OC step loss:  tensor(0., requires_grad=True)\n",
      "total training step loss:  tensor(1.8040, grad_fn=<AddBackward0>)\n",
      "batch 33 out of 2992\n",
      "batch_loss:  1.803990364074707\n",
      "Applying single optimization step on batch\n",
      "starting object condensation step...\n",
      "torch.Size([7594, 3])\n",
      "predictions torch.Size([7594, 12])\n",
      "alright buckaroo\n",
      "torch.Size([7594, 12])\n",
      "startin dynamic reduction step...\n",
      "clustering to dimension:  7594\n",
      "clustering to dimension:  3981\n",
      "DRN step loss:  tensor(1.8449, grad_fn=<NllLossBackward>)\n",
      "OC step loss:  tensor(0., requires_grad=True)\n",
      "total training step loss:  tensor(1.8449, grad_fn=<AddBackward0>)\n",
      "batch 34 out of 2992\n",
      "batch_loss:  1.8449079990386963\n",
      "Applying single optimization step on batch\n",
      "starting object condensation step...\n",
      "torch.Size([7599, 3])\n",
      "predictions torch.Size([7599, 12])\n",
      "alright buckaroo\n",
      "torch.Size([7599, 12])\n",
      "startin dynamic reduction step...\n",
      "clustering to dimension:  7599\n",
      "clustering to dimension:  3983\n",
      "DRN step loss:  tensor(1.8419, grad_fn=<NllLossBackward>)\n",
      "OC step loss:  tensor(0., requires_grad=True)\n",
      "total training step loss:  tensor(1.8419, grad_fn=<AddBackward0>)\n",
      "batch 35 out of 2992\n",
      "batch_loss:  1.8419345617294312\n",
      "Applying single optimization step on batch\n",
      "starting object condensation step...\n",
      "torch.Size([7654, 3])\n",
      "predictions torch.Size([7654, 12])\n",
      "alright buckaroo\n",
      "torch.Size([7654, 12])\n",
      "startin dynamic reduction step...\n",
      "clustering to dimension:  7654\n",
      "clustering to dimension:  4012\n",
      "DRN step loss:  tensor(1.8046, grad_fn=<NllLossBackward>)\n",
      "OC step loss:  tensor(0., requires_grad=True)\n",
      "total training step loss:  tensor(1.8046, grad_fn=<AddBackward0>)\n",
      "batch 36 out of 2992\n",
      "batch_loss:  1.8046376705169678\n",
      "Applying single optimization step on batch\n",
      "starting object condensation step...\n",
      "torch.Size([7759, 3])\n",
      "predictions torch.Size([7759, 12])\n",
      "alright buckaroo\n",
      "torch.Size([7759, 12])\n",
      "startin dynamic reduction step...\n",
      "clustering to dimension:  7759\n",
      "clustering to dimension:  4074\n",
      "DRN step loss:  tensor(1.7987, grad_fn=<NllLossBackward>)\n",
      "OC step loss:  tensor(0., requires_grad=True)\n",
      "total training step loss:  tensor(1.7987, grad_fn=<AddBackward0>)\n",
      "batch 37 out of 2992\n",
      "batch_loss:  1.7986799478530884\n",
      "Applying single optimization step on batch\n",
      "starting object condensation step...\n",
      "torch.Size([7711, 3])\n",
      "predictions torch.Size([7711, 12])\n",
      "alright buckaroo\n",
      "torch.Size([7711, 12])\n",
      "startin dynamic reduction step...\n",
      "clustering to dimension:  7711\n",
      "clustering to dimension:  4063\n",
      "DRN step loss:  tensor(1.8103, grad_fn=<NllLossBackward>)\n",
      "OC step loss:  tensor(0., requires_grad=True)\n",
      "total training step loss:  tensor(1.8103, grad_fn=<AddBackward0>)\n",
      "batch 38 out of 2992\n",
      "batch_loss:  1.8102502822875977\n",
      "Applying single optimization step on batch\n",
      "starting object condensation step...\n",
      "torch.Size([7432, 3])\n",
      "predictions torch.Size([7432, 12])\n",
      "alright buckaroo\n",
      "torch.Size([7432, 12])\n",
      "startin dynamic reduction step...\n",
      "clustering to dimension:  7432\n",
      "clustering to dimension:  3912\n",
      "DRN step loss:  tensor(1.7957, grad_fn=<NllLossBackward>)\n",
      "OC step loss:  tensor(0., requires_grad=True)\n",
      "total training step loss:  tensor(1.7957, grad_fn=<AddBackward0>)\n",
      "batch 39 out of 2992\n",
      "batch_loss:  1.7957265377044678\n",
      "Applying single optimization step on batch\n",
      "starting object condensation step...\n",
      "torch.Size([7632, 3])\n",
      "predictions torch.Size([7632, 12])\n",
      "alright buckaroo\n",
      "torch.Size([7632, 12])\n",
      "startin dynamic reduction step...\n",
      "clustering to dimension:  7632\n",
      "clustering to dimension:  4012\n",
      "DRN step loss:  tensor(1.7811, grad_fn=<NllLossBackward>)\n",
      "OC step loss:  tensor(0., requires_grad=True)\n",
      "total training step loss:  tensor(1.7811, grad_fn=<AddBackward0>)\n",
      "batch 40 out of 2992\n",
      "batch_loss:  1.7811152935028076\n",
      "Applying single optimization step on batch\n",
      "starting object condensation step...\n",
      "torch.Size([7681, 3])\n",
      "predictions torch.Size([7681, 12])\n",
      "alright buckaroo\n",
      "torch.Size([7681, 12])\n",
      "startin dynamic reduction step...\n",
      "clustering to dimension:  7681\n",
      "clustering to dimension:  4033\n",
      "DRN step loss:  tensor(1.7197, grad_fn=<NllLossBackward>)\n",
      "OC step loss:  tensor(0., requires_grad=True)\n",
      "total training step loss:  tensor(1.7197, grad_fn=<AddBackward0>)\n",
      "batch 41 out of 2992\n",
      "batch_loss:  1.719744086265564\n",
      "Applying single optimization step on batch\n",
      "starting object condensation step...\n",
      "torch.Size([7960, 3])\n",
      "predictions torch.Size([7960, 12])\n",
      "alright buckaroo\n",
      "torch.Size([7960, 12])\n",
      "startin dynamic reduction step...\n",
      "clustering to dimension:  7960\n",
      "clustering to dimension:  4180\n",
      "DRN step loss:  tensor(1.7239, grad_fn=<NllLossBackward>)\n",
      "OC step loss:  tensor(0., requires_grad=True)\n",
      "total training step loss:  tensor(1.7239, grad_fn=<AddBackward0>)\n",
      "batch 42 out of 2992\n",
      "batch_loss:  1.7239044904708862\n",
      "Applying single optimization step on batch\n",
      "starting object condensation step...\n",
      "torch.Size([7524, 3])\n",
      "predictions torch.Size([7524, 12])\n",
      "alright buckaroo\n",
      "torch.Size([7524, 12])\n",
      "startin dynamic reduction step...\n",
      "clustering to dimension:  7524\n",
      "clustering to dimension:  3959\n",
      "DRN step loss:  tensor(1.7335, grad_fn=<NllLossBackward>)\n",
      "OC step loss:  tensor(0., requires_grad=True)\n",
      "total training step loss:  tensor(1.7335, grad_fn=<AddBackward0>)\n",
      "batch 43 out of 2992\n",
      "batch_loss:  1.733538031578064\n",
      "Applying single optimization step on batch\n",
      "starting object condensation step...\n",
      "torch.Size([7534, 3])\n",
      "predictions torch.Size([7534, 12])\n",
      "alright buckaroo\n",
      "torch.Size([7534, 12])\n",
      "startin dynamic reduction step...\n",
      "clustering to dimension:  7534\n",
      "clustering to dimension:  3953\n",
      "DRN step loss:  tensor(1.7463, grad_fn=<NllLossBackward>)\n",
      "OC step loss:  tensor(0., requires_grad=True)\n",
      "total training step loss:  tensor(1.7463, grad_fn=<AddBackward0>)\n",
      "batch 44 out of 2992\n",
      "batch_loss:  1.7462764978408813\n",
      "Applying single optimization step on batch\n",
      "starting object condensation step...\n",
      "torch.Size([7628, 3])\n",
      "predictions torch.Size([7628, 12])\n",
      "alright buckaroo\n",
      "torch.Size([7628, 12])\n",
      "startin dynamic reduction step...\n",
      "clustering to dimension:  7628\n",
      "clustering to dimension:  4003\n",
      "DRN step loss:  tensor(1.6908, grad_fn=<NllLossBackward>)\n",
      "OC step loss:  tensor(0., requires_grad=True)\n",
      "total training step loss:  tensor(1.6908, grad_fn=<AddBackward0>)\n",
      "batch 45 out of 2992\n",
      "batch_loss:  1.6908124685287476\n",
      "Applying single optimization step on batch\n",
      "starting object condensation step...\n",
      "torch.Size([7740, 3])\n",
      "predictions torch.Size([7740, 12])\n",
      "alright buckaroo\n",
      "torch.Size([7740, 12])\n",
      "startin dynamic reduction step...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "clustering to dimension:  7740\n",
      "clustering to dimension:  4060\n",
      "DRN step loss:  tensor(1.6856, grad_fn=<NllLossBackward>)\n",
      "OC step loss:  tensor(0., requires_grad=True)\n",
      "total training step loss:  tensor(1.6856, grad_fn=<AddBackward0>)\n",
      "batch 46 out of 2992\n",
      "batch_loss:  1.6855642795562744\n",
      "Applying single optimization step on batch\n",
      "starting object condensation step...\n",
      "torch.Size([7633, 3])\n",
      "predictions torch.Size([7633, 12])\n",
      "alright buckaroo\n",
      "torch.Size([7633, 12])\n",
      "startin dynamic reduction step...\n",
      "clustering to dimension:  7633\n",
      "clustering to dimension:  4006\n",
      "DRN step loss:  tensor(1.7017, grad_fn=<NllLossBackward>)\n",
      "OC step loss:  tensor(0., requires_grad=True)\n",
      "total training step loss:  tensor(1.7017, grad_fn=<AddBackward0>)\n",
      "batch 47 out of 2992\n",
      "batch_loss:  1.7016711235046387\n",
      "Applying single optimization step on batch\n",
      "starting object condensation step...\n",
      "torch.Size([7541, 3])\n",
      "predictions torch.Size([7541, 12])\n",
      "alright buckaroo\n",
      "torch.Size([7541, 12])\n",
      "startin dynamic reduction step...\n",
      "clustering to dimension:  7541\n",
      "clustering to dimension:  3969\n",
      "DRN step loss:  tensor(1.6896, grad_fn=<NllLossBackward>)\n",
      "OC step loss:  tensor(0., requires_grad=True)\n",
      "total training step loss:  tensor(1.6896, grad_fn=<AddBackward0>)\n",
      "batch 48 out of 2992\n",
      "batch_loss:  1.6896268129348755\n",
      "Applying single optimization step on batch\n",
      "starting object condensation step...\n",
      "torch.Size([7616, 3])\n",
      "predictions torch.Size([7616, 12])\n",
      "alright buckaroo\n",
      "torch.Size([7616, 12])\n",
      "startin dynamic reduction step...\n",
      "clustering to dimension:  7616\n",
      "clustering to dimension:  3990\n",
      "DRN step loss:  tensor(1.6581, grad_fn=<NllLossBackward>)\n",
      "OC step loss:  tensor(0., requires_grad=True)\n",
      "total training step loss:  tensor(1.6581, grad_fn=<AddBackward0>)\n",
      "batch 49 out of 2992\n",
      "batch_loss:  1.6581424474716187\n",
      "Applying single optimization step on batch\n",
      "starting object condensation step...\n",
      "torch.Size([7656, 3])\n",
      "predictions torch.Size([7656, 12])\n",
      "alright buckaroo\n",
      "torch.Size([7656, 12])\n",
      "startin dynamic reduction step...\n",
      "clustering to dimension:  7656\n",
      "clustering to dimension:  4024\n",
      "DRN step loss:  tensor(1.6209, grad_fn=<NllLossBackward>)\n",
      "OC step loss:  tensor(0., requires_grad=True)\n",
      "total training step loss:  tensor(1.6209, grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-fc84417be59a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     84\u001b[0m \u001b[0mestim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mEstimator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss_func\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mloss_func\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcuda\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ml1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m \u001b[0;31m# fit the generator function to the estimator\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 86\u001b[0;31m \u001b[0mestim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_gen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgenfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_batches\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mn_train_batches\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_epochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mn_epochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilename\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'checkpoint.pt'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-7-05921c0fab5a>\u001b[0m in \u001b[0;36mfit_gen\u001b[0;34m(self, train_generator, n_batches, n_epochs, valid_generator, n_valid_batches, verbose, filename)\u001b[0m\n\u001b[1;32m    206\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_batches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    207\u001b[0m                 \u001b[0mbatch_input\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_target\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_generator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 208\u001b[0;31m                 batch_loss = (self.training_step(batch_input, batch_target)\n\u001b[0m\u001b[1;32m    209\u001b[0m                               .cpu().data.item())\n\u001b[1;32m    210\u001b[0m                 \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"batch {} out of {}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_batches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-7-05921c0fab5a>\u001b[0m in \u001b[0;36mtraining_step\u001b[0;34m(self, inputs, targets)\u001b[0m\n\u001b[1;32m    144\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    145\u001b[0m         \u001b[0;31m# backwards step\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 146\u001b[0;31m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    147\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    148\u001b[0m \u001b[0;31m#         scheduler.batch_step()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[1;32m    193\u001b[0m                 \u001b[0mproducts\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mDefaults\u001b[0m \u001b[0mto\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    194\u001b[0m         \"\"\"\n\u001b[0;32m--> 195\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    196\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    197\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[1;32m     97\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m     98\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 99\u001b[0;31m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m    100\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.simplefilter('ignore')\n",
    "\n",
    "# train_data = DataCollection(\"../data/train_data/dataCollection.djcdc\")\n",
    "# splits off 10% of the training dataset for validation. Can be used in the same way as train_data\n",
    "val_data = train_data.split(0.9) \n",
    "\n",
    "# Set the batch size. \n",
    "# If the data is ragged in dimension 1 (see convert options), \n",
    "# then this is the maximum number of elements per batch, which could be distributed differently\n",
    "# to individual examples. E.g., if the first example has 50 elements, the second 48, and the third 30,\n",
    "# and the batch size is set to 100, it would return the first two examples (in total 99 elements) in \n",
    "# the first batch etc. This is helpful to avoid out-of-memory errors during training\n",
    "\n",
    "batch_size = 500\n",
    "train_data.setBatchSize(batch_size)         \n",
    "    \n",
    "# prepare the generator\n",
    "train_data.invokeGenerator()\n",
    "train_data.generator.shuffleFilelist()\n",
    "# train_data.generator.prepareNextEpoch()\n",
    "\n",
    "# this number can differ from epoch to epoch for ragged data!\n",
    "n_train_batches = train_data.generator.getNBatches()\n",
    "\n",
    "# training data generator\n",
    "gen = train_data.generator\n",
    "\n",
    "def genfunc():\n",
    "    while(not gen.isEmpty()):\n",
    "        d = gen.getBatch()\n",
    "        yield d.transferFeatureListToNumpy() , d.transferTruthListToNumpy()\n",
    "\n",
    "# Model config\n",
    "hidden_dim = 20\n",
    "n_features = 6\n",
    "n_outputs = 12\n",
    "# number of particles per event... 1-9\n",
    "n_classes = 9\n",
    "k = 10\n",
    "n_epochs = 100\n",
    "# valid_frac = 0.1\n",
    "# test_frac = 0\n",
    "# epoch_size = len(train_data)\n",
    "# print(epoch_size, batch_size)\n",
    "\n",
    "print('features ->', n_features)\n",
    "print('classes ->', n_classes)\n",
    "print('hidden_dim = %d' % hidden_dim)\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        # input_dim is n_features = 6\n",
    "        # but if we feed predictions from OC into DRN instead of the features, then we use n_outputs = 12\n",
    "        self.drnoc = DRNOC(input_dim=n_outputs, hidden_dim=hidden_dim,\n",
    "                                           k=k,\n",
    "                                           output_dim=n_classes, aggr='add',\n",
    "                                           norm=torch.tensor([1./300.,1./200.,1./200.,1./100.,1./100.,1./100.]))\n",
    "\n",
    "    def forward(self, data):\n",
    "        DRN_logits, OC_logits = self.drnoc(data)\n",
    "        return F.log_softmax(DRN_logits, dim=1), OC_logits\n",
    "\n",
    "def print_model_summary(model):\n",
    "    \"\"\"Override as needed\"\"\"\n",
    "    print(\n",
    "        'Model: \\n%s\\nParameters: %i' %\n",
    "        (model, sum(p.numel() for p in model.parameters()))\n",
    "    )\n",
    "\n",
    "device = torch.device('cpu')\n",
    "model = Net().to(device)\n",
    "\n",
    "# # we don't need a scheduler because we explicitly put in the n_train_batches\n",
    "# optimizer = torch.optim.AdamW(model.parameters(), lr=1e-3, weight_decay=1e-3)\n",
    "# scheduler = CyclicLRWithRestarts(optimizer, batch_size, epoch_size, restart_period=400, t_mult=1.2, policy=\"cosine\")\n",
    "\n",
    "print_model_summary(model)\n",
    "\n",
    "# loss function, for no_grad case\n",
    "loss_func = nn.BCELoss()\n",
    "# initiate the estimator\n",
    "estim = Estimator(model, loss_func=loss_func, cuda=None, l1 = 0)\n",
    "# fit the generator function to the estimator\n",
    "estim.fit_gen(genfunc(), n_batches=n_train_batches, n_epochs=n_epochs, filename='checkpoint.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(estim.train_losses)\n",
    "print(estim.valid_losses)\n",
    "\n",
    "# Plot the loss\n",
    "plt.figure()\n",
    "plt.plot(estim.train_losses, label='training set')\n",
    "plt.plot(estim.valid_losses, label='validation set')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "#plt.xlim(195,300)\n",
    "#plt.ylim(.06,.08)\n",
    "plt.legend(loc=0);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
