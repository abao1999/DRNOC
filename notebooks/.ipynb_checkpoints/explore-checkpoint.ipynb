{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import uproot\n",
    "import awkward\n",
    "import numpy as np\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import networkx as nx\n",
    "\n",
    "import tempfile\n",
    "import atexit\n",
    "import os\n",
    "import pickle\n",
    "import imp\n",
    "\n",
    "from tqdm import tqdm_notebook as tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from DeepJetCore.DataCollection import DataCollection\n",
    "from DeepJetCore.compiled.c_trainDataGenerator import trainDataGenerator\n",
    "from DeepJetCore.customObjects import get_custom_objects\n",
    "# from DeepJetCore.training.gpuTools import DJCSetGPUs\n",
    "\n",
    "from keras.models import load_model\n",
    "from keras import backend as K"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plotting and Visualization Tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plotHist(axes, data, xlabel, ylabel, title, Nbins = 100, range=None, xlog=False, ylog=False):\n",
    "    axes.set_xlabel(xlabel)\n",
    "    axes.set_ylabel(ylabel)\n",
    "    axes.set_title(title)\n",
    "    if xlog:\n",
    "        axes.set_xscale('log')\n",
    "        Nbins = np.logspace(np.log10(data.min()),np.log10(data.max()),Nbins)\n",
    "    return axes.hist(data, bins=Nbins, range=range, histtype='step', log=ylog); \n",
    "    \n",
    "def plotHist_absxlog(axes, data, xlabel, ylabel, title, Nbins = 100, ylog=False):\n",
    "    axes.set_xlabel(xlabel)\n",
    "    axes.set_ylabel(ylabel)\n",
    "    axes.set_title(title)\n",
    "    axes.set_xscale('log')\n",
    "    Nbins = np.logspace(np.log10(np.abs(data).min()),np.log10(np.abs(data).max()),Nbins)\n",
    "    axes.hist(data, bins=Nbins, histtype='step', log=ylog); \n",
    "    \n",
    "def plotHist_layers(data, ylabel, title, xlabel=\"Layer\", log=True):\n",
    "    fig,axes = plt.subplots(figsize=(10, 7));\n",
    "    axes.set_xlabel(xlabel)\n",
    "    axes.set_xticks(np.arange(53)+0.5, minor=True)\n",
    "    axes.set_ylabel(ylabel)\n",
    "    axes.set_title(title)\n",
    "    axes.hist(data, range=(0,60), bins=np.arange(62)-0.5, log=log, histtype='step', linewidth = '1.5');\n",
    "    plt.grid(True, which='minor', axis='x', linewidth='0.5')\n",
    "    return fig"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preliminary Data Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<TrainData_PF.TrainData_PF_graph at 0x7fd394815500>"
      ]
     },
     "execution_count": 324,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputfile = '../data/train_data/100.djctd'\n",
    "\n",
    "# define train_data as our data collection, read from djcdc file\n",
    "train_data = DataCollection(\"../data/train_data/example_dataCollection.djcdc\")\n",
    "\n",
    "train_data.dataclass()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 325,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "features shape: \n",
      "(1, 2249, 200, 6)\n",
      "weights shape: \n",
      "(0,)\n",
      "truth shape: \n",
      "(1, 2249, 200, 11)\n"
     ]
    }
   ],
   "source": [
    "# define td as the train_data data collection's dataclass (i.e. TrainData_PF_graph)\n",
    "td = train_data.dataclass()\n",
    "td.readFromFile(inputfile)\n",
    "\n",
    "# dataclass contents: features, weights, truth\n",
    "features = td.transferFeatureListToNumpy()\n",
    "weights = td.transferWeightListToNumpy()\n",
    "truth = td.transferTruthListToNumpy()\n",
    "\n",
    "# actually convert to np array\n",
    "features_np = np.array(features)\n",
    "weights_np = np.array(weights)\n",
    "truth_np = np.array(truth)\n",
    "\n",
    "# print(\"FEATURES: \")\n",
    "# print(features_np)\n",
    "# print(\"WEIGHTS: \")\n",
    "# print(weights_np)\n",
    "# print(\"TRUTH: \")\n",
    "# print(truth_np)\n",
    "\n",
    "print(\"features shape: \")\n",
    "print(features_np.shape)\n",
    "print(\"weights shape: \")\n",
    "print(weights_np.shape)\n",
    "print(\"truth shape: \")\n",
    "print(truth_np.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Description\n",
    "Each cell/tracker sensor is assigned to exactly one truth particle, or labelled as noise. The sensor is assigned to the truth particle that leaves the largest energy deposit in that sensor; if this is less than 5% of the total truth particle energy, the sensor hit is labelled as noise. \n",
    "\n",
    "The 200 highest-energy hits are vertices in a graph. We use a GNN to predict the momentum and position of each particle alongside object condensation parameters. \n",
    "\n",
    "The inputs are energy an position information of each vertex. After one batch normalization layer on theinputs, the NN architecture consists of 6 subsequent blocks. In each block, the mean of all features is concatenated to the block input, followed by two dense layers, one batch normalization layer, and another dense layer. Dense layers have 64 nodes each and use elu activation functions. The output of the dense layers is fed through one GravNet layer. This layer is configured to project the input features to 4 latent spae dimensions and 64 features to be propagated from 10 neighbor vertices in the latent space. After aggregation, 128 output filters are applied. This output is then passed on to the next block and simultaneously compressed by one dense layer with 32 nodes and elu activation before it is added to a list of all block outputs. After 6 blocks, this final list, now with 192 features per vertex, is processed by one dense layer with 64 nodes and elu activation before the final NN outputs are predicted.\n",
    "\n",
    "Training dataset contains 1-9 particles per event, out of which 50% are electrons and 50% are photons. In total, 1.5 million events are used for training and 250,000 for validation. The model is trained with tensorflow, keras, and the DeepJetCore framework for 20 epochs with a learning rate of $3 \\cdot 10^{-4}$ and for 90 epochs with a learning rate of $3 \\cdot 10^{-5}$ using the Adam optimiser. The performance is evaluated on statistically independent test samples... condensation threshold: $t_{\\beta} = 0.1$ and $t_{d} = 0.8$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mapping"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Particle Loss Dictionary\n",
    "https://github.com/jkiesele/SOR/blob/317984a246d98e7d68d9b598745d0c9a3cedc596/modules/inference.py\n",
    "\n",
    "input features as\n",
    "B x V x F  already reshaped in network\n",
    "with F = colours\n",
    "and B = max number of samples in batch (not batch size!)\n",
    "(???) V = number of vertices?\n",
    "\n",
    "truth as \n",
    "B x P x T\n",
    "with T = [mask, true_posx, true_posy, ID_0, ID_1, ID_2, true_width, true_height, n_objects]\n",
    "(???) P = number of true partifles?\n",
    "\n",
    "all outputs in B x V x 1/F form except\n",
    "n_active: B x 1\n",
    "\n",
    "truth (???):\n",
    "\n",
    "outdict['t_mask'] =  truth[:,:,0:1]\n",
    "outdict['t_E']    =  truth[:,:,1:2]\n",
    "outdict['t_pos']  =  truth[:,:,2:4]\n",
    "outdict['t_ID']   =  truth[:,:,4:6]\n",
    "outdict['t_objidx']= truth[:,:,6:7]\n",
    "\n",
    "outdict['t_rhpos']= truth[:,:,7:10]\n",
    "outdict['t_rhid']= truth[:,:,10:11]\n",
    "\n",
    "isElectron,\n",
    "isGamma,\n",
    "isPositron,\n",
    "true_energy,\n",
    "true_x,\n",
    "true_y,\n",
    "etc (???)\n",
    "\n",
    "aka...\n",
    "\n",
    "t_mask\n",
    "t_energy\n",
    "t_x\n",
    "t_y\n",
    "t_iselectron\n",
    "t_isgamma\n",
    "t_idx\n",
    "i_rhx\n",
    "i_rhy\n",
    "i_rhz\n",
    "i_rhid\n",
    "\n",
    "features (???):\n",
    "\n",
    "rechit_energy,\n",
    "rechit_x,\n",
    "rechit_y,\n",
    "rechit_z,\n",
    "rechit_layer,\n",
    "rechit_detid,\n",
    "\n",
    "\n",
    "p_beta    = Dense(1,activation='sigmoid')(x)\n",
    "p_tpos    = ScalarMultiply(10.)(Dense(2)(x))\n",
    "p_ID      = Dense(2,activation='softmax')(x)\n",
    "p_E       = ScalarMultiply(10.)(Dense(1)(x))\n",
    "p_ccoords = ScalarMultiply(10.)(Dense(2)(x))\n",
    "\n",
    "predictions=Concatenate()([p_beta , # 0 \n",
    "                           p_E    ,  # 1\n",
    "                           p_tpos   , #2,3\n",
    "                           p_ID     , # 4,5\n",
    "                           p_ccoords, # 6,7\n",
    "                           ids,         #8 \n",
    "                           energy_raw]) # 9, 10(posx), 11(posy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_particle_dictionary(feat, truth, pred):\n",
    "    '''\n",
    "    input features as\n",
    "    B x V x F  already reshaped in network\n",
    "    with F = colours\n",
    "    and B = number of samples in batch (diff from batch size)\n",
    "    (???) V = number of vertices?\n",
    "\n",
    "    truth as \n",
    "    B x P x T\n",
    "    with T = [mask, true_posx, true_posy, ID_0, ID_1, ID_2, true_width, true_height, n_objects]\n",
    "    (???) P = number of true partifles?\n",
    "\n",
    "    all outputs in B x V x 1/F form except\n",
    "    n_active: B x 1\n",
    "    '''\n",
    "    outdict = {}\n",
    "\n",
    "    if truth is not None:\n",
    "        outdict['t_mask'] =  truth[:,:,0:1]\n",
    "        outdict['t_E']    =  truth[:,:,1:2]\n",
    "        outdict['t_pos']  =  truth[:,:,2:4]\n",
    "        outdict['t_ID']   =  truth[:,:,4:6]\n",
    "        outdict['t_objidx']= truth[:,:,6:7]\n",
    "\n",
    "        outdict['t_rhpos']= truth[:,:,7:10]\n",
    "        outdict['t_rhid']= truth[:,:,10:11]\n",
    "    #n_objects = truth[:,0,0,8]\n",
    "\n",
    "    if pred is not None:\n",
    "        outdict['p_beta']      =  pred[:,:,0:1]\n",
    "        outdict['p_E_corr']    =  pred[:,:,1:2]\n",
    "        outdict['p_pos_offs']  =  pred[:,:,2:4]\n",
    "        outdict['p_ID']        =  pred[:,:,4:6]\n",
    "\n",
    "        outdict['p_ccoords'] = pred[:,:,6:8]\n",
    "\n",
    "    if feat is not None:\n",
    "        outdict['f_E'] = feat[:,:,0:1]\n",
    "        outdict['f_pos'] = feat[:,:,1:3]\n",
    "        \n",
    "        # unsure but maybe include rechit_layer, rechit_detid ??... may be switched\n",
    "        outdict['f_ID'] = feat[:,:,3:5]\n",
    "        outdict['f_l'] = feat[:,:,5:6]\n",
    "        \n",
    "    return outdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 327,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['t_mask', 't_E', 't_pos', 't_ID', 't_objidx', 't_rhpos', 't_rhid', 'f_E', 'f_pos', 'f_ID', 'f_l'])\n",
      "t_mask dimensions: (2249, 200, 1)\n",
      "t_E dimensions: (2249, 200, 1)\n",
      "t_pos dimensions: (2249, 200, 2)\n",
      "t_ID dimensions: (2249, 200, 2)\n",
      "t_objidx dimensions: (2249, 200, 1)\n",
      "t_rhpos dimensions: (2249, 200, 3)\n",
      "t_rhid dimensions: (2249, 200, 1)\n",
      "f_E dimensions: (2249, 200, 1)\n",
      "f_pos dimensions: (2249, 200, 2)\n",
      "f_ID dimensions: (2249, 200, 2)\n",
      "f_l dimensions: (2249, 200, 1)\n"
     ]
    }
   ],
   "source": [
    "particle_dict = create_particle_dictionary(features_np[0], truth_np[0], None)\n",
    "print(particle_dict.keys())\n",
    "\n",
    "# truth dimensions\n",
    "for key, value in particle_dict.items():\n",
    "    print(\"{} dimensions: {}\".format(key, value.shape))\n",
    "\n",
    "# # print a view\n",
    "# print(particle_dict['t_E'][0][0:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 343,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2.1058379e+02 1.6901669e+02 1.3303032e+02 ... 1.2264234e-02 1.1864383e-02\n",
      " 1.1542415e-02]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(array([4.11764e+05, 1.09000e+04, 4.41100e+03, 2.57800e+03, 1.77300e+03,\n",
       "        1.31100e+03, 1.08100e+03, 8.29000e+02, 7.89000e+02, 6.36000e+02,\n",
       "        6.13000e+02, 5.28000e+02, 4.86000e+02, 4.52000e+02, 3.99000e+02,\n",
       "        3.98000e+02, 3.82000e+02, 3.61000e+02, 3.62000e+02, 3.20000e+02,\n",
       "        3.63000e+02, 3.28000e+02, 3.45000e+02, 3.00000e+02, 2.85000e+02,\n",
       "        2.98000e+02, 3.35000e+02, 3.03000e+02, 2.72000e+02, 2.97000e+02,\n",
       "        2.93000e+02, 2.85000e+02, 2.75000e+02, 2.54000e+02, 2.78000e+02,\n",
       "        2.40000e+02, 2.39000e+02, 2.55000e+02, 2.58000e+02, 2.45000e+02,\n",
       "        2.40000e+02, 2.05000e+02, 2.21000e+02, 2.00000e+02, 2.21000e+02,\n",
       "        2.19000e+02, 1.83000e+02, 1.57000e+02, 1.77000e+02, 1.63000e+02,\n",
       "        1.62000e+02, 1.32000e+02, 1.14000e+02, 9.20000e+01, 1.05000e+02,\n",
       "        8.20000e+01, 7.40000e+01, 6.70000e+01, 6.60000e+01, 6.40000e+01,\n",
       "        6.40000e+01, 6.30000e+01, 4.90000e+01, 4.90000e+01, 4.40000e+01,\n",
       "        4.70000e+01, 5.60000e+01, 3.80000e+01, 3.10000e+01, 2.00000e+01,\n",
       "        2.80000e+01, 2.80000e+01, 3.10000e+01, 2.50000e+01, 1.80000e+01,\n",
       "        2.70000e+01, 1.70000e+01, 1.30000e+01, 8.00000e+00, 8.00000e+00,\n",
       "        1.00000e+01, 1.00000e+01, 1.00000e+01, 5.00000e+00, 3.00000e+00,\n",
       "        8.00000e+00, 5.00000e+00, 2.00000e+00, 3.00000e+00, 3.00000e+00,\n",
       "        1.00000e+00, 2.00000e+00, 3.00000e+00, 1.00000e+00, 1.00000e+00,\n",
       "        1.00000e+00, 1.00000e+00, 0.00000e+00, 0.00000e+00, 2.00000e+00]),\n",
       " array([  0.      ,   2.801289,   5.602578,   8.403867,  11.205156,\n",
       "         14.006445,  16.807734,  19.609024,  22.410313,  25.211601,\n",
       "         28.01289 ,  30.81418 ,  33.615467,  36.41676 ,  39.21805 ,\n",
       "         42.019337,  44.820625,  47.621914,  50.423203,  53.22449 ,\n",
       "         56.02578 ,  58.827072,  61.62836 ,  64.42965 ,  67.230934,\n",
       "         70.03223 ,  72.83352 ,  75.6348  ,  78.4361  ,  81.23738 ,\n",
       "         84.03867 ,  86.83996 ,  89.64125 ,  92.442535,  95.24383 ,\n",
       "         98.04512 , 100.846405, 103.6477  , 106.44898 , 109.250275,\n",
       "        112.05156 , 114.85285 , 117.654144, 120.45543 , 123.25672 ,\n",
       "        126.05801 , 128.8593  , 131.66058 , 134.46187 , 137.26317 ,\n",
       "        140.06445 , 142.86574 , 145.66704 , 148.46832 , 151.2696  ,\n",
       "        154.07089 , 156.8722  , 159.67348 , 162.47476 , 165.27606 ,\n",
       "        168.07735 , 170.87863 , 173.67992 , 176.48122 , 179.2825  ,\n",
       "        182.08379 , 184.88507 , 187.68637 , 190.48766 , 193.28894 ,\n",
       "        196.09024 , 198.89153 , 201.69281 , 204.4941  , 207.2954  ,\n",
       "        210.09668 , 212.89796 , 215.69926 , 218.50055 , 221.30183 ,\n",
       "        224.10312 , 226.90442 , 229.7057  , 232.50699 , 235.30829 ,\n",
       "        238.10957 , 240.91086 , 243.71214 , 246.51344 , 249.31473 ,\n",
       "        252.11601 , 254.9173  , 257.7186  , 260.5199  , 263.32117 ,\n",
       "        266.12247 , 268.92374 , 271.72504 , 274.52634 , 277.3276  ,\n",
       "        280.1289  ], dtype=float32),\n",
       " <a list of 1 Patch objects>)"
      ]
     },
     "execution_count": 343,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1224x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# figs = []\n",
    "\n",
    "# def plotRechitEnergy(rechit_energy, title_target):\n",
    "#     title = \"Energy Distribution\"\n",
    "#     fig = plt.figure(figsize=(17,5))\n",
    "#     ax1 = fig.add_subplot(121)\n",
    "#     plotHist(ax1, rechit_energy, 'Energy/GeV', 'Rechits', title, Nbins = 100, ylog=True)\n",
    "#     ax2 = fig.add_subplot(122)\n",
    "#     plotHist(ax2, rechit_energy, 'Energy/GeV', 'Rechits', title, Nbins = 100, xlog=True, ylog=True)\n",
    "#     return fig\n",
    "\n",
    "#figs.append(plotRechitEnergy(e, \"Rechit\"))\n",
    "\n",
    "rechit_energy = np.reshape(particle_dict['f_E'], [-1])\n",
    "\n",
    "print(rechit_energy)\n",
    "\n",
    "fig = plt.figure(figsize=(17,5))\n",
    "ax1 = fig.add_subplot(121)\n",
    "plotHist(ax1, rechit_energy, 'Energy/GeV', 'Rechits', 'Energy Distribution (Log y)', Nbins = 100, ylog=True)\n",
    "# ax2 = fig.add_subplot(122)\n",
    "# plotHist(ax2, rechit_energy, 'Energy/GeV', 'Rechits', 'Energy Distribution (Log x)', Nbins = 100, xlog=True, ylog=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Object Condensation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Object Condensation Training Pipeline: Tensorflow Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clear td variable (so we don't interfere with later declarations in this notebook)\n",
    "td.clear()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import DeepJetCore\n",
    "# from DeepJetCore.training.training_base import training_base\n",
    "# from DeepJetCore.DataCollection import DataCollection\n",
    "# import keras\n",
    "# from keras.models import Model\n",
    "# from keras.layers import  Reshape, Dense,Conv1D, Conv2D, BatchNormalization, Multiply, Concatenate, Dropout,MaxPooling2D, $\n",
    "# from Layers import Conv2DGlobalExchange, PadTracker, CropTracker, TileCalo, GaussActivation, Tile2D, TileTrackerFeatures\n",
    "# from DeepJetCore.DJCLayers import ScalarMultiply, Clip, SelectFeatures, Print\n",
    "\n",
    "# from tools import plot_pred_during_training, plot_truth_pred_plus_coords_during_training, plot_particle_resolution_during_$\n",
    "# import tensorflow as tf\n",
    "# import os\n",
    "\n",
    "# from Layers import GravNet_simple, GlobalExchange\n",
    "# from Losses import particle_condensation_loss,dummy\n",
    "\n",
    "\n",
    "# # set training parameters\n",
    "# nbatch=550 #120 #1*7\n",
    "\n",
    "# plots_after_n_batch=1 #1000\n",
    "# use_event=0\n",
    "# learningrate=3e-4 #-4\n",
    "\n",
    "# momentum=0.6\n",
    "\n",
    "# # define output predictions format\n",
    "# def output_block(x,ids,energy_raw):\n",
    "#     p_beta    = Dense(1,activation='sigmoid')(x)\n",
    "#     p_tpos    = ScalarMultiply(10.)(Dense(2)(x))\n",
    "#     p_ID      = Dense(2,activation='softmax')(x)\n",
    "\n",
    "#     p_E       = (Dense(1)(x))\n",
    "#     p_ccoords = ScalarMultiply(10.)(Dense(2)(x))\n",
    "\n",
    "#     predictions=Concatenate()([p_beta ,\n",
    "#                                p_E    ,\n",
    "#                                p_tpos   ,\n",
    "#                                p_ID     ,\n",
    "#                                p_ccoords,\n",
    "#                                ids,\n",
    "#                                energy_raw])\n",
    "\n",
    "#     print('predictions',predictions.shape)\n",
    "#     return predictions\n",
    "\n",
    "# # get ids from features list ??\n",
    "# def checkids(Inputs):\n",
    "#     return SelectFeatures(5,6)(Inputs[0])\n",
    "\n",
    "# # define the model for training\n",
    "# def minimodel(Inputs,feature_dropout=-1.):\n",
    "#     x = Inputs[0] #this is the self.x list from the TrainData data structure\n",
    "#     energy_raw = SelectFeatures(0,3)(x)\n",
    "\n",
    "#     x = BatchNormalization(momentum=0.6)(x)\n",
    "#     feat=[x]\n",
    "\n",
    "#     for i in range(6):\n",
    "#         #add global exchange and another dense here\n",
    "#         x = GlobalExchange()(x)\n",
    "#         x = Dense(64, activation='elu')(x)\n",
    "#         x = Dense(64, activation='elu')(x)\n",
    "#         x = BatchNormalization(momentum=0.6)(x)\n",
    "#         x = Dense(64, activation='elu')(x)\n",
    "#         x = GravNet_simple(n_neighbours=10, \n",
    "#                  n_dimensions=4, \n",
    "#                  n_filters=128, \n",
    "#                  n_propagate=64)(x)\n",
    "#         x = BatchNormalization(momentum=0.6)(x)\n",
    "#         feat.append(Dense(32, activation='elu')(x))\n",
    "\n",
    "#     x = Concatenate()(feat)\n",
    "#     x = Dense(64, activation='elu')(x)\n",
    "\n",
    "#     return Model(inputs=Inputs, outputs=output_block(x,checkids(Inputs),energy_raw))\n",
    "\n",
    "# # initialize instance of training_base class\n",
    "# train=training_base(testrun=False,resumeSilently=True,renewtokens=False)\n",
    "\n",
    "# import os\n",
    "# os.system('cp /storage/user/abao/abao/SOR/modules/betaLosses.py '+train.outputDir+'/')\n",
    "\n",
    "# from tools import plot_pixel_3D_clustering_flat_during_training_graph\n",
    "\n",
    "# #samplepath = \"/data/hgcal-0/store/jkiesele/SOR/Dataset/test_wiggle/100.djctd\"\n",
    "# #samplepath = train.val_data.getSamplePath(train.val_data.samples[0])\n",
    "# samplepath = \"/storage/user/abao/abao/SOR/data/test_data/9.djctd\"\n",
    "\n",
    "# # weight decay function\n",
    "# def decay_function(ncalls):\n",
    "#     #print('call decay')\n",
    "#     #return 500\n",
    "#     if ncalls > 1000:\n",
    "#         return 500\n",
    "#     if ncalls > 200:\n",
    "#         return 50\n",
    "#     if ncalls > 100:\n",
    "#         return 20\n",
    "#     return 10\n",
    "\n",
    "# # resolution (??) weight  decay function\n",
    "# def reso_decay_function(ncalls):\n",
    "#     #print('call decay')\n",
    "#     #return 500\n",
    "#     if ncalls > 1000:\n",
    "#         return 3000\n",
    "#     if ncalls > 200:\n",
    "#         return 1000\n",
    "#     if ncalls > 100:\n",
    "#         return 50\n",
    "#     return 30\n",
    "\n",
    "# #only plots calo but fine\n",
    "# ppdts= [plot_pixel_3D_clustering_flat_during_training_graph(\n",
    "#                samplefile=samplepath,\n",
    "#                output_file=train.outputDir+'/train_progress'+str(i),\n",
    "#                use_event=use_event+i,\n",
    "#                afternbatches=plots_after_n_batch,\n",
    "#                on_epoch_end=False,\n",
    "#                mask=False,\n",
    "#                ccorrdsx_idx=6,\n",
    "#                ccorrdsy_idx=7,\n",
    "#                #cut_truth=16*16,\n",
    "#                assoindex=6,\n",
    "#                feat_x=1,\n",
    "#                feat_y=3,\n",
    "#                feat_z=2,\n",
    "#                decay_function=decay_function\n",
    "#                ) for i in range(5) ]\n",
    "\n",
    "# resoplot = plot_particle_resolution_during_training(\n",
    "#     outfilename=train.outputDir+'/resolution',\n",
    "#     samplefile=samplepath,\n",
    "#     after_n_batches=1,\n",
    "#     decay_function=reso_decay_function,\n",
    "#     use_event=-1\n",
    "#     )\n",
    "\n",
    "# # continue training from previous snapshot\n",
    "# if not train.modelSet(): # allows to resume a stopped/killed training. Only sets the model if it cannot be loaded from pre$\n",
    "\n",
    "#     #for regression use the regression model\n",
    "#     train.setModel(minimodel)#model)\n",
    "\n",
    "#     #read weights where possible from pretrained model\n",
    "#     #import os\n",
    "#     #from DeepJetCore.modeltools import load_model, apply_weights_where_possible\n",
    "#     #m_weights =load_model(os.environ['DEEPJETCORE_SUBPACKAGE'] + '/pretrained/gravnet_1.h5')\n",
    "#     #train.keras_model = apply_weights_where_possible(train.keras_model, m_weights)\n",
    "\n",
    "#     #for regression use a different loss, e.g. mean_squared_error\n",
    "\n",
    "# # compile model\n",
    "# train.compileModel(learningrate=learningrate,\n",
    "#                    #loss=dummy,\n",
    "#                    loss=particle_condensation_loss,\n",
    "#                    #clipnorm=1\n",
    "#                    )#metrics=[pixel_over_threshold_accuracy]) \n",
    "\n",
    "# # print model summary\n",
    "# print(train.keras_model.summary())\n",
    "# #exit()\n",
    "\n",
    "# # handle callbacks\n",
    "# print(len(ppdts))\n",
    "# ppdts_callbacks=[ppdts[i].callback for i in range(len(ppdts))]\n",
    "# ppdts_callbacks.append(resoplot)\n",
    "\n",
    "# verbosity=2\n",
    "\n",
    "# #train.change_learning_rate(learningrate/10.)\n",
    "# model,history = train.trainModel(nepochs=20, \n",
    "#                                  batchsize=int(nbatch),\n",
    "#                                  checkperiod=10, # saves a checkpoint model every N epochs\n",
    "#                                  verbose=verbosity,\n",
    "#                                  additional_callbacks=ppdts_callbacks)\n",
    "# print('reducing learning rate')\n",
    "# train.change_learning_rate(learningrate/10.)\n",
    "\n",
    "# model,history = train.trainModel(nepochs=100+20, \n",
    "#                                  batchsize=nbatch,\n",
    "#                                  checkperiod=10, # saves a checkpoint model every N epochs\n",
    "#                                  verbose=verbosity,\n",
    "#                                  additional_callbacks=ppdts_callbacks)\n",
    "\n",
    "# print('reducing learning rate')\n",
    "# train.change_learning_rate(learningrate/10.)\n",
    "\n",
    "# model,history = train.trainModel(nepochs=200, \n",
    "#                                  batchsize=nbatch,\n",
    "#                                  checkperiod=10, # saves a checkpoint model every N epochs\n",
    "#                                  verbose=verbosity,\n",
    "#                                  additional_callbacks=ppdts_callbacks)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import subprocess\n",
    "\n",
    "# os.getcwd()\n",
    "# # SOR_dir = \"/storage/user/abao/abao/SOR\"\n",
    "# train_bashCommand = \"python3 ../Train/train.py ../data/train_data/dataCollection.djcdc ../results_1\"\n",
    "# process = subprocess.Popen(train_bashCommand.split(), stdout=subprocess.PIPE)\n",
    "# output, error = process.communicate()\n",
    "# print(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Object Condensation Prediction Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clear td variable (so we don't interfere with later declarations in this notebook)\n",
    "td.clear()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pred (None, 200, 12)\n",
      "Mki (None, 200, None)\n",
      "kalpha (None, None)\n",
      "x_kalpha <unknown>\n",
      "Mki (None, 200, None)\n",
      "kalpha (None, None)\n",
      "x_kalpha <unknown>\n",
      "Mki (None, 200, None)\n",
      "kalpha (None, None)\n",
      "x_kalpha <unknown>\n",
      "Mki (None, 200, None)\n",
      "kalpha (None, None)\n",
      "x_kalpha <unknown>\n",
      "Mki (None, 200, None)\n",
      "kalpha (None, None)\n",
      "x_kalpha <unknown>\n",
      "Mki (None, 200, None)\n",
      "kalpha (None, None)\n",
      "x_kalpha <unknown>\n",
      "Mki (None, 200, None)\n",
      "kalpha (None, None)\n",
      "x_kalpha <unknown>\n",
      "Mki (None, 200, None)\n",
      "kalpha (None, None)\n",
      "x_kalpha <unknown>\n",
      "Mki (None, 200, None)\n",
      "kalpha (None, None)\n",
      "x_kalpha <unknown>\n",
      "Nobj (None,)\n",
      "Nobj (None,)\n",
      "../data/train_data/1.djctd\n",
      "../data/train_data/predictions/pred_1.djctd\n",
      "predicting  ../data/train_data/1.djctd\n",
      "batch size 1\n",
      "WARNING:tensorflow:From <ipython-input-13-8a2de9295dfd>:51: Model.predict_generator (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use Model.predict, which supports generators.\n",
      "2249/2249 [==============================] - 24s 11ms/step\n"
     ]
    }
   ],
   "source": [
    "### see https://github.com/DL4Jets/DeepJetCore/blob/master/bin/predict.py\n",
    "\n",
    "# prediction outputs\n",
    "outputs = []\n",
    "\n",
    "# get batchsize from train_data data collection\n",
    "batchsize = -1\n",
    "\n",
    "# DJCSetGPUs(args.gpu)\n",
    "\n",
    "# use as input model a previously (partially) trained model with same train_data data collection\n",
    "inputModel = \"../results_partial/KERAS_check_best_model.h5\"\n",
    "custom_objs = get_custom_objects()\n",
    "model = load_model(inputModel, custom_objects=custom_objs)\n",
    "\n",
    "# File Paths\n",
    "# file that we are generating predictions for\n",
    "inputfile = '../data/train_data/1.djctd'\n",
    "# same directory as input file\n",
    "outputDir = os.path.dirname(inputfile) + \"/predictions\"\n",
    "outputfilename = \"pred_\"+os.path.basename(inputfile)\n",
    "outputfile = outputDir + \"/\" + outputfilename\n",
    "print(inputfile)\n",
    "print(outputfile)\n",
    "\n",
    "# define td as the train_data data collection's dataclass (i.e. TrainData_PF_graph)\n",
    "td = train_data.dataclass()\n",
    "td.readFromFile(inputfile)\n",
    "\n",
    "# define training data generator class instance gen and set its variables\n",
    "print('predicting ',inputfile)\n",
    "gen = trainDataGenerator()\n",
    "if batchsize < 1:\n",
    "    batchsize = train_data.getBatchSize()\n",
    "print('batch size', batchsize)\n",
    "gen.setBatchSize(batchsize)\n",
    "gen.setSquaredElementsLimit(train_data.batch_uses_sum_of_squares)\n",
    "gen.setSkipTooLargeBatches(False)\n",
    "gen.setBuffer(td)\n",
    "\n",
    "# data generator function\n",
    "def genfunc():\n",
    "    while(not gen.isEmpty()):\n",
    "        d = gen.getBatch()\n",
    "        yield d.transferFeatureListToNumpy() , d.transferTruthListToNumpy()\n",
    "\n",
    "# predictions\n",
    "predicted = model.predict_generator(genfunc(),\n",
    "                                    steps=gen.getNBatches(),\n",
    "                                    max_queue_size=1,\n",
    "                                    use_multiprocessing=False,verbose=1)\n",
    "\n",
    "# dataclass contents: features, weights, truth\n",
    "# note: must convert these to numpy at the end of we mess things up\n",
    "features = td.transferFeatureListToNumpy()\n",
    "weights = td.transferWeightListToNumpy()\n",
    "truth = td.transferTruthListToNumpy()\n",
    "\n",
    "# actually convert to np array\n",
    "features_np = np.array(features)\n",
    "weights_np = np.array(weights)\n",
    "truth_np = np.array(truth)\n",
    "\n",
    "# clear variables\n",
    "td.clear()\n",
    "gen.clear()\n",
    "\n",
    "if not type(predicted) == list: #circumvent that keras return only an array if there is just one list item\n",
    "    predicted = [predicted]   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predictions=Concatenate()([p_beta , # 0 \n",
    "#                            p_E    ,  # 1\n",
    "#                            p_tpos   , #2,3\n",
    "#                            p_ID     , # 4,5\n",
    "#                            p_ccoords, # 6,7\n",
    "#                            ids,         #8 \n",
    "#                            energy_raw]) # 9, 10(posx), 11(posy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PREDICTIONS: \n",
      "writeout\n",
      "predicted (2249, 200, 12)\n",
      "features (2249, 200, 6)\n",
      "truth (2249, 200, 11)\n",
      "sample view of predicted: \n",
      "[ 9.9358219e-01  8.9633167e-01 -1.4621300e-01 -3.9307162e-01\n",
      "  8.0293244e-01  1.9706748e-01 -1.8932699e+00 -4.7628803e+00\n",
      "  2.0260000e+03  2.0539420e+02 -2.4750000e+01  5.7750000e+01]\n",
      "sample view of truth: \n",
      "[ 1.0000000e+00  1.9737604e+02 -2.3920635e+01  5.5204815e+01\n",
      "  1.0000000e+00  0.0000000e+00  2.0000000e+00 -2.4750000e+01\n",
      "  5.7750000e+01 -4.9700001e+01  2.0260000e+03]\n"
     ]
    }
   ],
   "source": [
    "print(\"PREDICTIONS: \")\n",
    "# print(predicted)\n",
    "\n",
    "predicted_np = np.array(predicted)\n",
    "\n",
    "td.writeOutPrediction(predicted, features, truth, weights, outputfile, inputfile)\n",
    "        \n",
    "outputs.append(outputfilename)\n",
    "\n",
    "print(\"sample view of predicted: \")\n",
    "print(predicted_np[0][0][0])\n",
    "print(\"sample view of truth: \")\n",
    "print(truth_np[0][0][0])\n",
    "\n",
    "with open(outputDir + \"/outfiles.txt\",\"w\") as f:\n",
    "    for l in outputs:\n",
    "        f.write(l+'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['t_mask', 't_E', 't_pos', 't_ID', 't_objidx', 't_rhpos', 't_rhid', 'p_beta', 'p_E_corr', 'p_pos_offs', 'p_ID', 'p_ccoords', 'f_E', 'f_pos', 'f_ID', 'f_l'])\n",
      "t_mask dimensions: (2249, 200, 1)\n",
      "t_E dimensions: (2249, 200, 1)\n",
      "t_pos dimensions: (2249, 200, 2)\n",
      "t_ID dimensions: (2249, 200, 2)\n",
      "t_objidx dimensions: (2249, 200, 1)\n",
      "t_rhpos dimensions: (2249, 200, 3)\n",
      "t_rhid dimensions: (2249, 200, 1)\n",
      "p_beta dimensions: (2249, 200, 1)\n",
      "p_E_corr dimensions: (2249, 200, 1)\n",
      "p_pos_offs dimensions: (2249, 200, 2)\n",
      "p_ID dimensions: (2249, 200, 2)\n",
      "p_ccoords dimensions: (2249, 200, 2)\n",
      "f_E dimensions: (2249, 200, 1)\n",
      "f_pos dimensions: (2249, 200, 2)\n",
      "f_ID dimensions: (2249, 200, 2)\n",
      "f_l dimensions: (2249, 200, 1)\n"
     ]
    }
   ],
   "source": [
    "particle_dict = create_particle_dictionary(features_np[0], truth_np[0], predicted_np[0])\n",
    "print(particle_dict.keys())\n",
    "\n",
    "# truth dimensions\n",
    "for key, value in particle_dict.items():\n",
    "    print(\"{} dimensions: {}\".format(key, value.shape))\n",
    "\n",
    "# # print a view\n",
    "# print(particle_dict['p_beta'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sample predicted energy correction (p_E_corr) from predicted: \n",
      "[[0.89633167]\n",
      " [1.2975289 ]\n",
      " [1.3342274 ]\n",
      " [0.98950076]\n",
      " [1.833063  ]]\n",
      "sample truth energy (t_E) from truth: \n",
      "[[197.37604 ]\n",
      " [197.37604 ]\n",
      " [171.38068 ]\n",
      " [ 84.529854]\n",
      " [ 84.529854]]\n"
     ]
    }
   ],
   "source": [
    "print(\"sample predicted energy correction (p_E_corr) from predicted: \")\n",
    "print(particle_dict['p_E_corr'][0][0:5])\n",
    "print(\"sample truth energy (t_E) from truth: \")\n",
    "print(particle_dict['t_E'][0][0:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([2.0000e+00, 0.0000e+00, 5.0000e+00, 1.2000e+01, 1.8000e+01,\n",
       "        4.0000e+01, 5.5000e+01, 1.0300e+02, 1.5500e+02, 1.9000e+02,\n",
       "        2.9600e+02, 3.9500e+02, 5.7100e+02, 6.1300e+02, 8.5700e+02,\n",
       "        1.0410e+03, 1.2040e+03, 1.4320e+03, 1.6440e+03, 1.9330e+03,\n",
       "        2.1600e+03, 2.4860e+03, 2.9680e+03, 3.4340e+03, 3.9310e+03,\n",
       "        4.7060e+03, 5.4590e+03, 6.3340e+03, 7.2810e+03, 8.0330e+03,\n",
       "        8.7390e+03, 9.4140e+03, 1.0058e+04, 1.0336e+04, 1.0855e+04,\n",
       "        1.1241e+04, 1.1232e+04, 1.1203e+04, 1.1124e+04, 1.1131e+04,\n",
       "        1.0728e+04, 1.0282e+04, 1.0494e+04, 1.0411e+04, 1.0408e+04,\n",
       "        1.0291e+04, 1.0227e+04, 1.0351e+04, 1.0520e+04, 1.0288e+04,\n",
       "        1.0332e+04, 1.0770e+04, 1.3406e+04, 1.0183e+04, 9.2110e+03,\n",
       "        8.9190e+03, 8.6450e+03, 8.0350e+03, 7.7510e+03, 7.3870e+03,\n",
       "        6.4980e+03, 6.2680e+03, 6.0270e+03, 5.5760e+03, 5.3250e+03,\n",
       "        4.9920e+03, 4.7210e+03, 4.5160e+03, 4.3720e+03, 4.1640e+03,\n",
       "        3.9640e+03, 3.7900e+03, 3.5470e+03, 3.3770e+03, 3.0390e+03,\n",
       "        2.9280e+03, 2.5340e+03, 2.2740e+03, 1.9190e+03, 1.6860e+03,\n",
       "        1.4080e+03, 1.1900e+03, 9.6500e+02, 8.0200e+02, 6.6400e+02,\n",
       "        5.7600e+02, 4.2600e+02, 2.7600e+02, 2.1600e+02, 1.4600e+02,\n",
       "        9.7000e+01, 7.7000e+01, 3.4000e+01, 2.8000e+01, 2.4000e+01,\n",
       "        7.0000e+00, 4.0000e+00, 5.0000e+00, 6.0000e+00, 2.0000e+00]),\n",
       " array([-2.8459253 , -2.7725806 , -2.6992362 , -2.6258914 , -2.5525467 ,\n",
       "        -2.4792023 , -2.4058576 , -2.3325129 , -2.2591681 , -2.1858237 ,\n",
       "        -2.112479  , -2.0391343 , -1.9657897 , -1.8924451 , -1.8191004 ,\n",
       "        -1.7457558 , -1.6724112 , -1.5990665 , -1.5257219 , -1.4523772 ,\n",
       "        -1.3790326 , -1.305688  , -1.2323433 , -1.1589987 , -1.085654  ,\n",
       "        -1.0123094 , -0.9389648 , -0.86562014, -0.79227555, -0.7189309 ,\n",
       "        -0.64558625, -0.5722416 , -0.498897  , -0.42555234, -0.35220772,\n",
       "        -0.27886307, -0.20551844, -0.1321738 , -0.05882917,  0.01451547,\n",
       "         0.08786011,  0.16120474,  0.23454937,  0.30789402,  0.38123864,\n",
       "         0.4545833 ,  0.52792794,  0.6012726 ,  0.6746172 ,  0.7479618 ,\n",
       "         0.82130647,  0.8946511 ,  0.96799576,  1.0413404 ,  1.114685  ,\n",
       "         1.1880296 ,  1.2613742 ,  1.334719  ,  1.4080635 ,  1.4814082 ,\n",
       "         1.5547528 ,  1.6280974 ,  1.7014421 ,  1.7747867 ,  1.8481314 ,\n",
       "         1.921476  ,  1.9948206 ,  2.0681653 ,  2.14151   ,  2.2148545 ,\n",
       "         2.2881992 ,  2.361544  ,  2.4348884 ,  2.508233  ,  2.5815778 ,\n",
       "         2.6549225 ,  2.728267  ,  2.8016117 ,  2.8749564 ,  2.9483008 ,\n",
       "         3.0216455 ,  3.0949903 ,  3.1683347 ,  3.2416794 ,  3.3150241 ,\n",
       "         3.3883686 ,  3.4617133 ,  3.535058  ,  3.6084027 ,  3.6817472 ,\n",
       "         3.755092  ,  3.8284366 ,  3.901781  ,  3.9751258 ,  4.0484705 ,\n",
       "         4.121815  ,  4.19516   ,  4.268504  ,  4.341849  ,  4.4151936 ,\n",
       "         4.4885383 ], dtype=float32),\n",
       " <a list of 1 Patch objects>)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAeYAAAFNCAYAAADVSMziAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+j8jraAAAgAElEQVR4nO3de7hcdX3v8ffXCBpAd1pBW0Ni1E2p8W63QA+eqtRLECLVqg3eSovkWA9qT6+xeqo9Hmt4rHcRTwSKVgqiFiWQClTkcKQIBMQLIkq5NIkKeEkqGKXC9/yx1g7DMHvvmeyZvS7zfj3PPJm11sya75qZzGev3++31orMRJIk1cMDqi5AkiTdy2CWJKlGDGZJkmrEYJYkqUYMZkmSasRgliSpRgxmqcEi4r9GxPUVvv61EfGsIa3rFRFxQcd0RsTkMNZdru+OiHjMsNbXte53RsQfj2Ldg4qIB0XEtyJiv6pr0e4xmDUyEXFzROwsfxCnbx+quq65ROENEfGNiLgzIrZGxKci4ok1qO0+YZWZ/y8zDxzB66woX2v6c7s1Is6NiOd2Pi4zH5+ZF/e5rgfO9rjMPD0znzeE8omIiyPiNV3r3yczbxzG+rteaz/g1cD/KaefFRFbh/06/crMnwOnAuuqqkHzYzBr1FaXP4jTt+OH/QJz/eDvhvcDbwTeAPwy8GvAZ4EjBl1Rr9oiYtF8C1xASzJzH+DJwIXA2RFxzLBfZASf4UI6BtiUmTurLqTDPwK/HxEPqroQ7YbM9OZtJDfgZuA5Myw7BvgS8HfAj4GbgMM7lk8ApwDfA7YB/xtY1PHcS4H3Aj8slz0M2Aj8B3BlOe9L5eNPBN7d9frnAP+jR10HAHcDB82yXRPAx4HbgVuAtwAPmKW204CTgE3AncBzgEcCnynXcRPwho71LwL+Cvg34CfAVcAy4BIgy3XcAfwe8Cxga8dzHwdcDGwHrgVe2LHstPK9OK9c7+XAY2fYxhXlaz2wa/6fAbd2bO+uzxg4CNhcfga3Au8p5/97ua47yttvzvA+HTP9mZXPS4o/jm4EfgC8q+N13wZ8ole9wDvKz/Bn5et9qGN9k31+hjN+N3u8VxcBr+yYvs9n0vXY2T6fGb/DPdZzHvD6rnlfA17UMf0d4JlV/w54G/xWeQHe2ntj7mD+T+A4iiD6I+C7QJTLz6ZoGtwbeDhwBfDfOp77C+D15Q/xYuDM8rYXsBLYwr3BfFC57ukf3n2BnwKP6FHXa4Fb5tiujwOfAx5SBsK3gWNnqe00YAdwKEUr1V4UYfvXwJ7AYyjC5/nlOv4c+DpwIBAUe6sPK5ftCpdyelcIAHsAN1CE+p7AYRQBfGC5/DSKEDyorO104MwZtnEFvYP5MeX8x3V/xsBlwKvK+/sAh8y0rhnep2O4fzB/kaLVYnn5Pr+mXPY2Zgjmcvri6cd2rW+yz89wxu9mj/fqduDpvT6TrsfN9fnM+B3usa6XAZd3TD+5/Gz37Jh3Dh1/8Hlrzs2mbI3aZyNie8ftuI5lt2TmRzPzbuBjwK8Cj4iIRwAvAP44M+/MzNso9qzWdDz3u5n5wcz8BXAX8LvAWzPzp5n5zXJ9AGTmFRTB+NvlrDXAxZl5a496H0axl95T2Qy9BnhTZv4kM28G3g28qldteW/z5ucy89LMvAd4IrBfZv6vzLwri37Pj3Zs32uAt2Tm9Vn4amb+cKaaOhxCEYjry/VeBJwLHN3xmLMz84ryfTsdeEof6+303fLfX+6x7D+ByYjYNzPvyMwvz7WuHu9TtxMy80eZ+e/A+7jvtuyWPj/Dnt/NGVa5hCJg5zLj51PWNON3uIdzgF+LiAPK6VcBn8zMuzoe85OyNjWMwaxR+53MXNJx+2jHsu9P38nMn5Z39wEeRbF38b3pQKfYe354x3O3dNzfj2Kva8sMy6H4kXtlef+VwD/MUO8PKX6EZ7JvWdstHfNuAZbO8trd8x4FPLLzDxaKvajpH/5lFM3Yg3oksKUM/5lq+37H/Z9SvN+DmF7Xj3osO5aiP/5bEXFlRBw5x7p6vU+zPeYWim2cr34+w5m+m738mGLPey6zfT79fId3ycyfAZ8EXhkRD6D4g6X7O/0QiiZzNYzBrDraAvwc2Lcj0B+amY/veEznZdFup2gW3b9j3rKudX4COCoinkzRz/fZGV77C8D+ETE1w/IfUOwZPqpj3nKKfvBetfWatwW4qesPlodk5gs6lj92htefzXeBZeUP9Uy1zdeLgNuA+x2ilZnfycyjKf6AOgH4dETsTe/3g1nmd+r8HJdz7x77nRRNvtN+ZYB19/MZDuJrFH+QzGW2z6ef73C3jwGvoGgJ+mlmXta1/HHAV/uoSzVjMKt2MvN7wAXAuyPioRHxgIh4bEQ8c4bH3w38E/C2iNgrIn6d4vCVzsdspRhQ8w/AZ2ZqOs3M7wAfBs4oD3vZMyIeHBFrImJd+VpnAe+IiIdExKOAP6EI/n5dAfwkIv4yIhZHxKKIeEJEPL1cfjLw9og4oDx060kR8bBy2a0U/by9XE6xF/wXEbFHeXzxaop+y3mJiEdExPHAWymagO/p8ZhXRsR+5bLpPbV7KELnnlnqns2fR8QvRcQyipHynyznXwP8VkQsj4gJ4E1dz5vxfRrSZ9hpE3C/72b5vdl1o/jce34+/XyHe2zHZRTv67vp2luOiKUU3Q1zdSeohgxmjdrGruOYz+7zea+mGCDzTYqmwk8zexPz8RQjbb9P8SN1BsVed6ePUfTvztSMPe0NwIcoRjBvp2hWfhHFiFkoBizdSTFg60sUh6ac2sc2AbuC4UiK/t2bKPbgTi7rB3gPRXBcQDFC9xSKwVFQDHr6WNkE/rKu9d5F8UN/eLnODwOvzsxv9VtbD9sj4k6KwWgvAF6amTNt6yrg2oi4g+KQszWZubNsCn4HcGlZ9yEDvP7nKAbKXUMxEvkUgMy8kCKkv1YuP7free8HXhIRP46ID/RY77w+wy4fB14QEYs75i0FdnbdljH759PPd7jXaz+R+/9R8XLgY1kc06yGmR4BK7VKRJwA/Epm/n7HvN+i+AF7VPrF1xBFxN8Ct2Xm+4a4zvt9h3s85tXA2sx8Rse8B1E0Yf9WOXBSDdPkg/qlXcqmvz0p9uyeTjEQ6TUdy/egaAo92VDWsGXmX813HXN9h3s8fi/gdRR73p21/Bz49fnWo+rYlK22eAhFH92dFE2c76ZoBiUiHkfRJP2rFIfcSHU043e4W0Q8n6Lv/laKZni1iE3ZkiTViHvMkiTViMEsSVKNNH7w17777psrVqyougxJkvp21VVX/SAze14zu7HBHBGrgdWTk5Ns3ry56nIkSepbRNwy07LGNmVn5sbMXDsxMTH3gyVJaojGBrMkSW1kMEuSVCMGsyRJNWIwS5JUIwazJEk1YjBLklQjBrMkSTViMEuSVCMGsyRJNdLYU3JKqtah6y9i2/adu6aXLlnMpesOq7AiqR0MZkm7Zdv2ndy8/ohd0yvWnVdhNVJ72JQtSVKNGMySJNWIwSxJUo3Uro85IvYG/i/wtsw8t+p6pG7dg57m4qAoSYMYeTBHxKnAkcBtmfmEjvmrgPcDi4CTM3N9uegvgbNGXZfUr16jjzsHPfXz/JkGRjUptHu9D5KGbyH2mE8DPgR8fHpGRCwCTgSeC2wFroyIc4ClwDeBBy9AXVJfukcfD2q24O0O7e6gHvXe+SCHPM33fZDUn5EHc2ZeEhErumYfBNyQmTcCRMSZwFHAPsDewEpgZ0Rsysx7Rl2jxttc4TfKPcPuEOwV1MPaO++le/1z7d3Pta7Z/siQ1J+q+piXAls6prcCB2fm8QARcQzwg5lCOSLWAmsBli9fPtpK1Xp12hOcb5BV+fzu53pcs7R7ajf4CyAzT5tj+QZgA8DU1FQuRE1qD/tKJdVZVcG8DVjWMb1/OU8auTrtIbeZTdvS7qkqmK8EDoiIR1ME8hrg5YOsICJWA6snJydHUJ7axD3kavTTf25QS/cXmaNtCY6IM4BnAfsCtwJvzcxTIuIFwPsoDpc6NTPfsTvrn5qays2bNw+rXLXQinXnuYdcQ14EQ+MsIq7KzKleyxZiVPbRM8zfBGwa9etLqicHi0m91XLwVz9sytZMbLpuJvukpcLIm7JHzaZsdbPpuh1s6labVdqULY2ae8jt5OAxjSuDWY3n4U/jwT5pjYvGXvYxIlZHxIYdO3ZUXYokSUPT2GDOzI2ZuXZiYqLqUiRJGhqbstU49ikLHMWt9jKY1Tj2KQscHKb2amwwexyzpE4GtdqiscGcmRuBjVNTU8dVXYuk+nEUt5qqscEsSYPo7JN271l1ZjCr9hzspWHoDGKbuVVnBrNqz8FeGjabuVVnjQ1mB39JGhYPvVKdNDaYHfwlaVjcg1adNDaY1W6d/cr2KWuhuQetKhnMqiX7lVUlj4lWlQxmSZqDQa2FZDBL0oAMao1SY4PZUdmS6sLBYxqmxgazo7LbxZOIqE0cPKb5aGwwq10c7KU2salb82EwS9KI2dStQRjMkrTAbOrWbAxmVcI+ZY0zm7o1G4NZlbBPWbqXTd3q9ICqC5AkSfdq7B6zxzFLaiv7oMdbZGbVNczL1NRUbt68ueoyNIdefcr+0Ej96b6oi/93mi8irsrMqV7LGrvHrGaxT1nafZ1BbP9z+9nHLElSjRjMkiTViE3ZktQgDgxrP4NZI+EJRKTR8Jjn9jOYNRIO9pKk3WMwS1KD2bTdPgazJDWYTdvtYzBrKOxTlqThMJg1FPYpS9JwNPY45ohYHREbduzYUXUpkiQNTWP3mDNzI7BxamrquKprGUc2XUv15GCw5mtsMKtaNl1L9eRgsOZrbFO2JEltZDBLklQjNmWrL/YpS81kn3PzGMzqi33KUjPZ59w8NmVLklQjBrMkSTViU7Z6sk9ZkqphMKsn+5SldnIwWP0ZzJI0RhwMVn/2MUuSVCMGsyRJNWJTtgAHe0njyj7n+qlVMEfE44A3AvsCX8jMkyouaWw42EsaT/Y518/Im7Ij4tSIuC0ivtE1f1VEXB8RN0TEOoDMvC4zXwu8DDh01LVJklQ3C9HHfBqwqnNGRCwCTgQOB1YCR0fEynLZC4HzgE0LUJskSbUy8qbszLwkIlZ0zT4IuCEzbwSIiDOBo4BvZuY5wDkRcR7wj6Oub1zZpyxJ9VRVH/NSYEvH9Fbg4Ih4FvBi4EHMssccEWuBtQDLly8fXZUtZp+yJNVTrQZ/ZebFwMV9PG4DsAFgamoqR1uVJI0PR2lXr6pg3gYs65jev5wnSaqQo7SrV9UJRq4EDoiIR0fEnsAa4JxBVhARqyNiw44dO0ZSoCRJVRj5HnNEnAE8C9g3IrYCb83MUyLieOB8YBFwamZeO8h6M3MjsHFqauq4YdfcRg72kqRmWIhR2UfPMH8THhK1YBzsJUnNUKvBX4OIiNXA6snJyapLkaTWcjDYwmtsMNuULUmj52CwhefVpSRJqhGDWZKkGmlsMHu4lCSpjRobzJm5MTPXTkxMVF2KJElD09jBX5Kkheco7dEzmCVJfXOU9ug1Npg9jnlunWf78kxfktQMjQ1mj2Oem2f7kqTmaWww6/48H7akhWaf8/AZzC3iHrKkhWaf8/A19nApSZLayGCWJKlGGhvMnvlLktRGjQ1mz/wlSWqjxgazJEltZDBLklQjHi4lSRoaj2ueP4NZkjQ0Htc8f40NZs+V7Zm+JKmNGhvMnivbM31JUhs5+EuSpBoxmCVJqhGDWZKkGukrmKOwbNTFSJI07voK5sxMYNOIa5EkaewN0pR9dUQ8fWSVSJKkgQ6XOhh4RUTcAtwJBMXO9JNGUtkcxvE4Zo9blqT26yuYIyKAtcAtoy2nf+N4HLPHLUtS+/UVzJmZEXFiZj5x1AVJktqj89zZnje7P4M0ZV8dEU/PzCtHVo0kqVU6g9jzZvensX3MkiS10SDB/PyRVSFJkoABDpfKzFuAJcDq8raknCdJkoak72COiDcCpwMPL2+fiIjXj6owSZLG0SBN2ccCB2fmnQARcQJwGfDBURQmSdI4GiSYA7i7Y/rucp4kSXPqPHRqetrDp+5vkGD+e+DyiDi7nP4d4JThlyRJaqPuEPbwqd76DubMfE9EXAw8o5z1B5n5lZFU1YdxPCWnJKn9Bhn8dQjwncz8QGZ+APi3iDh4dKXNLjM3ZubaiYmJqkqQJGnoBmnKPgl4Wsf0HT3maYi8aIUkjZ+BBn+V12UGIDPviYhBnq8BedEKSRo/g1yP+caIeENE7FHe3gjcOKrCJEkaR4ME82uB/wJsA7ZSnDt77SiKkiRpXA0yKvs2YM1MyyPiTZn5zqFUJUnSmBpmH/FLAYN5HhzsJUkaZjB7FrB5crCXJGmYwZxzP0SSpIKn6OzNPWZJUiU8RWdvg4zKnsunhrguSZLG0pzBHBFnddw/oWvZBdP3M/Nvh1uaJEnjp5895gM67j+3a9l+Q6xFkqSx108wzzaoywFfkiQNUT+Dv/aKiKdShPji8n6UNw+0lSRpiPoJ5u8B7ynvf7/j/vT00ETE7wBHAA8FTsnMC+Z4iiRJrTJnMGfms/tZUUQ8NzMv7DH/VOBI4LbMfELH/FXA+4FFwMmZuT4zPwt8NiJ+Cfg7wGCWJI2VYR4udcIM808DVnXOiIhFwInA4cBK4OiIWNnxkLeUyyVJGisjP8FIZl4SESu6Zh8E3JCZNwJExJnAURFxHbAe+OfMvHqItdWS58aWJHWr6pScS4EtHdPTl5F8PfAcYCIiJjPzI72eHBFrKS85uXz58t2rtgY8N7Ykqdswg3neMvMDwAf6eNwGYAPA1NSUh2xJUgt47uxC38EcEQ8GXgc8g2Lv+EvASZn5s/IhNw/wutuAZR3T+5fzJEljynNnFwYZ/PVx4PHAB4EPUQza+ofphZn54gHWdSVwQEQ8OiL2BNYA5wzwfCJidURs2LFjxyBPkySp1gYJ5idk5rGZ+cXydhxFUM8qIs4ALgMOjIitEXFsZv4COB44H7gOOCszrx2k8MzcmJlrJyYmBnmaJEm1Nkgf89URcUhmfhkgIg4GNs/1pMw8eob5m4BNA7y+JEmtN0gw/wbwrxHx7+X0cuD6iPg6kJn5pKFXN4uIWA2snpycXMiXlSRppAYJ5lVzP2ThZOZGYOPU1NRxVdciSRq+cR2l3XcwZ+YtoyxEkqRO4zpKe5in5JQkSfPU2GD2cClJUhs1Npg9XEqS1EaNDWZJktrIYJYkqUYaG8z2MUuS2qixwWwfsySpjWp12ce2O3T9RWzbvnPX9NIliyusRpJURwbzAtq2fSc3rz+i6jIkSTXW2KZsSZLaqLHB7OAvSVIbNTaYHfwlSWqjxgazJEltZDBLklQjBrMkSTViMEuSVCONPY45IlYDqycnJ6suZUaeUESSNKjGBnNmbgQ2Tk1NHVd1LTPxhCKSpEHZlC1JUo0YzJIk1YjBLElSjTS2j1mSNF6WLlnMinXn3Wf60nWHVVjRaBjMkqRG6A7hzpBuE5uyJUmqkcYGs1eXkiS1UWOD2atLSZLayD5mSVIjtXUwmMEsSWqktg4Ga2xTtiRJbWQwS5JUIwazJEk1Yh+zJKkV2jIYzGCWJLVCWwaD2ZQtSVKNGMySJNWIwSxJUo00Npg9V7YkqY0aG8yeK1uS1EaNDWZJktrIw6WG6ND1F7Ft+85d00uXLK6wGklSExnMQ7Rt+05uXn9E1WVIkhrMpmxJkmrEYJYkqUYMZkmSasRgliSpRgxmSZJqxGCWJKlGDGZJkmrEYJYkqUYMZkmSasQzf82Dp+CUJA1brYI5Ih4DvBmYyMyXVF3PXDwFpyRp2EbelB0Rp0bEbRHxja75qyLi+oi4ISLWAWTmjZl57KhrkiSprhaij/k0YFXnjIhYBJwIHA6sBI6OiJULUIskSbU28mDOzEuAH3XNPgi4odxDvgs4Ezhq1LVIklR3VY3KXgps6ZjeCiyNiIdFxEeAp0bEm2Z6ckSsjYjNEbH59ttvH3WtkiQtmFoN/srMHwKv7eNxG4ANAFNTUznquiRJWihV7TFvA5Z1TO9fzpMkaaxVFcxXAgdExKMjYk9gDXDOICuIiNURsWHHjh0jKVCSpCosxOFSZwCXAQdGxNaIODYzfwEcD5wPXAeclZnXDrLezNyYmWsnJiaGX7QkSRUZeR9zZh49w/xNwKZRv74kSU3iubIlSaqRxgazfcySpDZqbDDbxyxJaqPGBrMkSW1UqxOMDCIiVgOrJycnqy5FklRDS5csZsW68+4zfem6wyqsqD+NDebM3AhsnJqaOq7qWiRJ9dMdwp0hXWc2ZUuSVCMGsyRJNWIwS5JUI43tY3bwlyRpmA5dfxHbtu/cNV3VYLHGBrODvyRJw7Rt+05uXn/ErumqBovZlC1JUo0YzJIk1YjBLElSjTS2j7mKwV+9BgZIkpqprr/pjQ3mKgZ/dQ8MkCQ1V11/023KliSpRgxmSZJqxGCWJKlGDGZJkmqksYO/PCWnJGkQva7PXEeNDWZPySlJGkQV573eHTZlS5JUIwazJEk1YjBLklQjBrMkSTViMEuSVCMGsyRJNdLYYI6I1RGxYceOHVWXIknS0DQ2mDNzY2aunZiYqLoUSZKGprHBLElSGxnMkiTViMEsSVKNGMySJNWIwSxJUo0YzJIk1YjBLElSjRjMkiTViMEsSVKNPLDqAnZXRKwGVk9OTg51vYeuv4ht23cCsHTJYi5dd9hQ1y9JaoalSxazYt1595leiExobDBn5kZg49TU1HHDXO+27Tu5ef0RAPf5QCRJ46U7hBcqE2zKliSpRgxmSZJqxGCWJKlGDGZJkmrEYJYkqUYMZkmSasRgliSpRgxmSZJqxGCWJKlGDGZJkmrEYJYkqUYiM6uuYV4i4nbglj4fvi/wgxGWU5U2blcbtwnauV1t3CZo53a5TfXxqMzcr9eCxgfzICJic2ZOVV3HsLVxu9q4TdDO7WrjNkE7t8ttagabsiVJqhGDWZKkGhm3YN5QdQEj0sbtauM2QTu3q43bBO3cLrepAcaqj1mSpLobtz1mSZJqbeyCOSLeHhFfi4hrIuKCiHhk1TXNV0S8KyK+VW7X2RGxpOqahiEiXhoR10bEPRHR6FGXEbEqIq6PiBsiYl3V9QxDRJwaEbdFxDeqrmVYImJZRHwxIr5ZfvfeWHVNwxARD46IKyLiq+V2/U3VNQ1LRCyKiK9ExLlV1zIsYxfMwLsy80mZ+RTgXOCvqy5oCC4EnpCZTwK+Dbyp4nqG5RvAi4FLqi5kPiJiEXAicDiwEjg6IlZWW9VQnAasqrqIIfsF8KeZuRI4BPjvLfmsfg4clplPBp4CrIqIQyquaVjeCFxXdRHDNHbBnJn/0TG5N9D4TvbMvCAzf1FOfhnYv8p6hiUzr8vM66uuYwgOAm7IzBsz8y7gTOCoimuat8y8BPhR1XUMU2Z+LzOvLu//hOIHf2m1Vc1fFu4oJ/cob43/7YuI/YEjgJOrrmWYxi6YASLiHRGxBXgF7dhj7vSHwD9XXYTuYymwpWN6Ky34sW+7iFgBPBW4vNpKhqNs8r0GuA24MDPbsF3vA/4CuKfqQoaplcEcEf8SEd/ocTsKIDPfnJnLgNOB46uttj9zbVP5mDdTNMWdXl2lg+lnu6SFFhH7AJ8B/rirla2xMvPusgtvf+CgiHhC1TXNR0QcCdyWmVdVXcuwPbDqAkYhM5/T50NPBzYBbx1hOUMx1zZFxDHAkcBvZ4OOgRvgs2qybcCyjun9y3mqoYjYgyKUT8/Mf6q6nmHLzO0R8UWK8QFNHrh3KPDCiHgB8GDgoRHxicx8ZcV1zVsr95hnExEHdEweBXyrqlqGJSJWUTTnvDAzf1p1PbqfK4EDIuLREbEnsAY4p+Ka1ENEBHAKcF1mvqfqeoYlIvabPlojIhYDz6Xhv32Z+abM3D8zV1D8n7qoDaEMYxjMwPqyqfRrwPMoRvQ13YeAhwAXloeBfaTqgoYhIl4UEVuB3wTOi4jzq65pd5QD844HzqcYTHRWZl5bbVXzFxFnAJcBB0bE1og4tuqahuBQ4FXAYeX/pWvKPbKm+1Xgi+Xv3pUUfcytObyobTzzlyRJNTKOe8ySJNWWwSxJUo0YzJIk1YjBLElSjRjMkiTViMEsNURE3N1xCM81VV+lKiI+EhGHlvf/pLzC2dfLKxi9pzxRx0zPfWtEvLNr3lMiolUXI5B2RyvP/CW11M7ylIpDExEP7LgAyqCmr770WopzAhxSnlVqT+BPgMXAf87w3DOAz3PfK6GtKedLY809ZqnhIuLmiPibiLi63GP99XL+3uU1k68or1d7VDn/mIg4JyIuAr4QEXtFxFnlNYjPjojLI2IqIv4wIt7X8TrHRcR7y/uPA76dmXcDbwb+KDO3A2TmXZm5fvoc0xHxvIi4rKzvUxGxT2Z+G/hxRBzcsSkvw2CWDGapQRZ3NWX/XseyH2Tm04CTgD8r572Z4jSFBwHPBt4VEXuXy54GvCQznwm8DvhxeQ3i/wn8RvmYs4DVHU3SfwCcWt4/HPh8RDwU2Cczb+pVcETsC7wFeE5Z32aKvWkoQnhN+bhDgB9l5nd2432RWsWmbKk5ZmvKnr7YwlXAi8v7z6M4yf90UD8YWF7evzAzp6+l/Azg/QCZOX26WjLzjnKv+siy73ePzPx6+ZznUwT1fUTE84ETgCXAy4FfBlYClxanoWZPitN4AnwS+NeI+FNsxpZ2MZildvh5+e/d3Pv/OoDfzczrOx9YNh/f2ed6Twb+iuKCB39fPn8vYElmfrecviMiHp2ZN2Xm+cD5EXEuRQgHxR8BR3evODO3RMRNwDOB36U4J7o09mzKltrrfOD15RWTiIinzvC4Syn6d4mIlcATpxdk5uUUl6x8Offu0T4b+GLH898JnNRx9aKg2DsH+DJwaERMlsv2johf63juGcB7gRszc+tubqfUKu4xS82xOCKu6Zj+fGbOdsjU24H3AV+LiAcAN1Fcs7vbh4GPRcQ3KfaMrwV2dCw/C3hKZv64nD4c+HTH8pOAvYHLI+LnwB0UYf+VzNxRXiv8jIh4UPn4twDfLu9/CvgA8PpZtkMaK15dShpzEbGIonRymrkAAABvSURBVP/4ZxHxWOBfgAMz865y+bnAezPzC+X01cDBmTnToVCS5sE9Zkl7UVyrdw+KPuHXZeZdZdP0FcBXp0MZoBxdLWlE3GOWJKlGHPwlSVKNGMySJNWIwSxJUo0YzJIk1YjBLElSjRjMkiTVyP8HwuUY4wnmmzcAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 1224x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "p_E_corr = np.reshape(particle_dict['p_E_corr'],[-1])\n",
    "    \n",
    "fig = plt.figure(figsize=(17,5))\n",
    "ax1 = fig.add_subplot(121)\n",
    "plotHist(ax1, p_E_corr, 'Energy/GeV', 'p_E_corr', 'Energy Correction Distribution (Log y)', Nbins = 100, ylog=True)\n",
    "# ax2 = fig.add_subplot(122)\n",
    "# plotHist(ax2, p_E_corr, 'Energy/GeV', 'Rechits', 'Energy Distribution (Log x)', Nbins = 100, xlog=True, ylog=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Condensate Particles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # collect_condensates as defined in inference\n",
    "# def collect_condensates(data, \n",
    "#                           beta_threshold, distance_threshold):\n",
    "    \n",
    "#     betas   = np.reshape(data['p_beta'], [data['p_beta'].shape[0], -1])\n",
    "#     ccoords = np.reshape(data['p_ccoords'], [data['p_ccoords'].shape[0], -1, data['p_ccoords'].shape[-1]])\n",
    "    \n",
    "#     sorting = np.argsort(-betas, axis=1)\n",
    "    \n",
    "#     betasel = betas > beta_threshold\n",
    "    \n",
    "#     bsel =  c_collectoverthresholds(betas, \n",
    "#                             ccoords, \n",
    "#                             sorting,\n",
    "#                             betasel,\n",
    "#                           beta_threshold, distance_threshold)\n",
    "    \n",
    "    \n",
    "# return np.reshape(bsel , data['p_beta'].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inputfile ../data/train_data/predictions/pred_1.djctd\n",
      "predictions shape:  (2249, 200, 12)\n",
      "number of events:  2249\n",
      "event property names:  jet_mass_r_pu0.0, jet_mass_t_pu0.0, p_imbalance_x_r_pu0.0, p_imbalance_x_t_pu0.0,jet_mass_r_pu0.2, jet_mass_t_pu0.2, p_imbalance_x_r_pu0.2, p_imbalance_x_t_pu0.2,jet_mass_r_pu0.5, jet_mass_t_pu0.5, p_imbalance_x_r_pu0.5, p_imbalance_x_t_pu0.5,jet_mass_r_pu0.8, jet_mass_t_pu0.8, p_imbalance_x_r_pu0.8, p_imbalance_x_t_pu0.8,n_true, e_access_n\n",
      "all particles shape:  (11412, 10)\n",
      "all events shape:  (2249, 18)\n",
      "efficiency:  0.5474012069301148\n",
      "fake:  0.16829340431824905\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "from DeepJetCore.TrainData import TrainData\n",
    "\n",
    "from evaluation_tools import find_best_matching_truth_and_format, write_output_tree, determine_event_properties, write_event_output_tree\n",
    "from inference import make_particle_inference_dict,  collect_condensates\n",
    "\n",
    "\n",
    "allparticles=[]\n",
    "all_ev_prop=[]\n",
    "names=\"\"\n",
    "\n",
    "inputFileDir = \"../data/train_data/predictions\"\n",
    "inputFile = \"../data/train_data/predictions/outfiles.txt\"\n",
    "outputFile = \"../data/train_data/predictions/condensates_1\"\n",
    "\n",
    "with open(inputFile) as file:\n",
    "    for inputfile in file:\n",
    "        inputfile = inputfile.replace('\\n', '')\n",
    "        inputfile = inputFileDir + '/' + inputfile\n",
    "        if len(inputfile)<1: continue\n",
    "\n",
    "        print('inputfile', inputfile)\n",
    "\n",
    "        td = TrainData()\n",
    "        td.readFromFile(inputfile)\n",
    "        indata = td.transferFeatureListToNumpy()\n",
    "        pred, feat, truth = indata[0],indata[1],indata[2]\n",
    "        del td\n",
    "\n",
    "        d = make_particle_inference_dict(pred, feat, truth)\n",
    "        condensate_mask = np.squeeze(collect_condensates(d, 0.1, 0.8),axis=2) #B x V x 1\n",
    "\n",
    "        pred_E   = d['f_E']* d['p_E_corr']\n",
    "        pred_pos = d['f_pos'] + d['p_pos_offs']\n",
    "        calo_energy = None #not supported by data format..\n",
    "        #np.sum(d['f_E'][:,0:16*16,0],axis=-1)#calo energy\n",
    "        #loop over events here.. easier\n",
    "        \n",
    "        print(\"predictions shape: \", pred.shape)\n",
    "        nevents = pred.shape[0]\n",
    "        all_idxs = np.array([i for i in range(pred.shape[1])])\n",
    "\n",
    "        #print('pred_pos',pred_pos.shape)\n",
    "        #print('all_idxs',all_idxs.shape)\n",
    "        \n",
    "        # read more at: https://github.com/jkiesele/SOR/blob/master/modules/evaluation_tools.py\n",
    "        for event in range(nevents):\n",
    "            ev_pred_E    = pred_E[event][condensate_mask[event]>0][:,0]\n",
    "            ev_pred_pos  = pred_pos[event][condensate_mask[event]>0]\n",
    "            ev_truth = truth[event]\n",
    "            ob_idx = all_idxs[condensate_mask[event]>0]\n",
    "            \n",
    "            # matched_posx, matched_posy, matched_e, matched_id, not_recoed_pos, not_recoed_e, not_recoed_id\n",
    "            eventparticles = find_best_matching_truth_and_format(ev_pred_pos, ev_pred_E, ob_idx, ev_truth)\n",
    "            allparticles.append(eventparticles)\n",
    "\n",
    "            ev_pro, names = determine_event_properties(eventparticles, None)\n",
    "            all_ev_prop.append(ev_pro)\n",
    "print(\"number of events: \", nevents)\n",
    "print(\"event property names: \", names)\n",
    "allparticles = np.concatenate(allparticles,axis=0)\n",
    "all_ev_prop = np.concatenate(all_ev_prop,axis=0)\n",
    "print(\"all particles shape: \", allparticles.shape)\n",
    "print(\"all events shape: \", all_ev_prop.shape)\n",
    "\n",
    "#is_reco, reco_posx, reco_posy, reco_e, is_true, true_posx, true_posy, true_e, true_id\n",
    "print('efficiency: ', float(np.count_nonzero( allparticles[:,0] *  allparticles[:,4]))/float( np.count_nonzero(allparticles[:,4] ) ))\n",
    "print('fake: ', float(np.count_nonzero( allparticles[:,0] *  (1.-allparticles[:,4])))/float( np.count_nonzero(allparticles[:,0] ) ))\n",
    "\n",
    "write_output_tree(allparticles, outputFile)\n",
    "write_event_output_tree(all_ev_prop, names, outputFile)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot visualizations of condensates "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# same thing as make_particle_resolution_plots in tools.py in modules, but modified to show inline in notebook\n",
    "def custom_make_particle_resolution_plots(feat,predicted,truth):\n",
    "    from inference import make_particle_inference_dict, collect_condensates\n",
    "    d = make_particle_inference_dict(predicted, feat , truth)\n",
    "    # B x V x F\n",
    "    pred_E   = d['f_E']* d['p_E_corr']\n",
    "    pred_pos = d['f_pos'] + d['p_pos_offs']\n",
    "        \n",
    "    condensate_mask = collect_condensates(d, 0.1, 0.8) #B x V x 1\n",
    "    condensate_mask = np.reshape(condensate_mask, [condensate_mask.shape[0],condensate_mask.shape[1]]) #B x V \n",
    "    \n",
    "    print(\"condensate_mask shape: \", condensate_mask.shape)\n",
    "    \n",
    "    n_condensates = np.sum(condensate_mask, axis=-1, keepdims=True) #B x 1\n",
    "    \n",
    "    # get number of true particles for each event(?) by taking maximum of true object ids (t_objidx) among V dim\n",
    "    n_true_particles = np.reshape(np.max(d['t_objidx'],axis=1)+1., [d['t_objidx'].shape[0],1])  #B x 1 x 1\n",
    "    \n",
    "    \n",
    "    print(\"n_condensates\")\n",
    "    print(\"n_condensates shape: \", n_condensates.shape)\n",
    "    print(n_condensates)\n",
    "    print(\"n_true_particles\")\n",
    "    print(\"n_true_particles shape: \", n_true_particles.shape)\n",
    "    print(n_true_particles)\n",
    "    \n",
    "    \n",
    "    n_total_condensates = np.sum(n_condensates)\n",
    "    \n",
    "    print(\"n_total_condensates\")\n",
    "    print(n_total_condensates)\n",
    "    \n",
    "    n_total_true_particles = np.sum(n_true_particles)\n",
    "    print(\"n_total_true_particles\")\n",
    "    print(n_total_true_particles)\n",
    "        \n",
    "    print('fraction of right number: ',float(np.sum(n_condensates==n_true_particles))/float(n_true_particles.shape[0]))\n",
    "    \n",
    "    # flatten to 1-D representation\n",
    "    flat_cond_mask =  np.reshape(condensate_mask, [-1])\n",
    "        \n",
    "    flat_E_true = np.reshape(d['t_E'],[-1])\n",
    "    flat_E_pred = np.reshape(pred_E,[-1])\n",
    "        \n",
    "    E_resolution = flat_E_pred*flat_cond_mask/(flat_E_true+0.0001) # B x V x 1\n",
    "    #E_variance = \n",
    "        \n",
    "    E_resolution = E_resolution[flat_cond_mask>0]\n",
    "    sel_E_true = flat_E_true[flat_cond_mask>0]\n",
    "    \n",
    "    \n",
    "    #energy resolution\n",
    "    fig = plt.figure(figsize=(18, 6))\n",
    "    axs = [fig.add_subplot(1,2,1),\n",
    "            fig.add_subplot(1,2,2)]\n",
    "    \n",
    "    axs[0].hist(E_resolution,bins=29, range=[0.93,1.07])\n",
    "    axs[1].hist2d(sel_E_true,E_resolution,bins=21, range=[[0,200],[0.9,1.1]])\n",
    "    \n",
    "    axs[0].set_title(\"Energy Resolution\")\n",
    "    axs[0].set_xlabel(\"Energy Resolution\")\n",
    "    axs[0].set_ylabel(\"Count\")\n",
    "    \n",
    "    axs[1].set_title(\"Energy Resolution vs. True Energy\")\n",
    "    axs[1].set_xlabel(\"Energy/GeV\")\n",
    "    axs[1].set_ylabel(\"Energy Resolution\")\n",
    "    \n",
    "    plt.show()\n",
    "    \n",
    "#     fig.savefig(outfile, dpi=300)\n",
    "    \n",
    "#     fig.clear()\n",
    "#     plt.close(fig)\n",
    "#     plt.clf()\n",
    "#     plt.cla()\n",
    "#     plt.close() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pred (2249, 200, 12)\n",
      "feat (2249, 200, 6)\n",
      "truth (2249, 200, 11)\n",
      "condensate_mask shape:  (2249, 200)\n",
      "n_condensates\n",
      "n_condensates shape:  (2249, 1)\n",
      "[[5]\n",
      " [3]\n",
      " [3]\n",
      " ...\n",
      " [2]\n",
      " [3]\n",
      " [4]]\n",
      "n_true_particles\n",
      "n_true_particles shape:  (2249, 1)\n",
      "[[7.]\n",
      " [4.]\n",
      " [7.]\n",
      " ...\n",
      " [3.]\n",
      " [4.]\n",
      " [6.]]\n",
      "n_total_condensates\n",
      "6762\n",
      "n_total_true_particles\n",
      "10000.0\n",
      "fraction of right number:  0.09337483325922633\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1296x432 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# matplotlib as mpl imported earlier\n",
    "mpl.use('Agg') \n",
    "# from tools import make_particle_resolution_plots\n",
    "\n",
    "inputFile = \"../data/train_data/predictions/pred_1.djctd\"\n",
    "\n",
    "#just read the stored data\n",
    "td = TrainData()\n",
    "td.readFromFile(inputFile)\n",
    "indata = td.transferFeatureListToNumpy()\n",
    "pred, feat, truth = indata[0],indata[1],indata[2]\n",
    "del td\n",
    "\n",
    "print('pred',pred.shape)\n",
    "print('feat',feat.shape)\n",
    "print('truth',truth.shape)\n",
    "\n",
    "# make_particle_resolution_plots(feat, pred, truth, outfile=\"reso.pdf\")\n",
    "custom_make_particle_resolution_plots(feat, pred, truth)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from wand.image import Image as WImage\n",
    "# img = WImage(filename='reso.pdf')\n",
    "# img"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Explore Condensate Output Files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dynamic Reduction Network with Object Condensation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # data structure class for training... mimics C-like struct\n",
    "# class DRN_TrainData_PF():\n",
    "#     def __init__(self, x=None, batch=None):\n",
    "#         # features\n",
    "#         self.x = x\n",
    "# #         # targets\n",
    "# #         self.y = y\n",
    "#         # tensor assigning batches to nodes\n",
    "#         self.batch = batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 5.0018e+02,  6.0139e+02, -2.6360e+04,  ..., -2.0235e+04,\n",
       "          7.0000e+00,  0.0000e+00],\n",
       "        [ 2.8792e+02,  3.4471e+02,  1.5791e+04,  ...,  3.7511e+03,\n",
       "          4.0000e+00,  0.0000e+00],\n",
       "        [ 1.2328e+02,  5.7804e+02,  9.9223e+03,  ..., -6.5212e+03,\n",
       "          7.0000e+00,  0.0000e+00],\n",
       "        ...,\n",
       "        [ 2.6284e+02,  3.3529e+02,  6.4947e+03,  ...,  2.6220e+03,\n",
       "          3.0000e+00,  0.0000e+00],\n",
       "        [ 3.3423e+02,  4.1547e+02, -3.4433e+04,  ..., -1.9189e+04,\n",
       "          4.0000e+00,  0.0000e+00],\n",
       "        [ 6.0678e+02,  7.1857e+02, -4.6898e+03,  ..., -7.7536e+03,\n",
       "          6.0000e+00,  0.0000e+00]])"
      ]
     },
     "execution_count": 300,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# all events from object condensation\n",
    "all_ev_prop_tensor = torch.from_numpy(all_ev_prop)\n",
    "all_ev_prop_tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Estimator for Pytorch Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 350,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "This module contains the Estimator class implementation which provides\n",
    "code for doing the training of a PyTorch model.\n",
    "\"\"\"\n",
    "\n",
    "from __future__ import print_function\n",
    "\n",
    "from datetime import datetime\n",
    "from timeit import default_timer as timer\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import shutil \n",
    "import os\n",
    "import copy \n",
    "\n",
    "import torch\n",
    "\n",
    "from torch_geometric.data import Batch      \n",
    "\n",
    "from Losses import particle_condensation_loss\n",
    "\n",
    "def logger(s):\n",
    "    \"\"\"Simple logger function which prints date/time\"\"\"\n",
    "    print(datetime.now(), s)\n",
    "\n",
    "class Estimator():\n",
    "    \"\"\"Estimator class\"\"\"\n",
    "\n",
    "    def __init__(self, model, loss_func, opt='Adam',\n",
    "                 train_losses=None, valid_losses=None,\n",
    "                 cuda=False, l1=0.):\n",
    "\n",
    "        self.model = model\n",
    "        if cuda:\n",
    "            self.model.cuda()\n",
    "        self.loss_func = loss_func\n",
    "        if opt == 'Adam':\n",
    "            self.optimizer = torch.optim.Adam(self.model.parameters())\n",
    "        elif opt == 'SGD':\n",
    "            self.optimizer = torch.optim.SGD(self.model.parameters())\n",
    "\n",
    "        self.train_losses = train_losses if train_losses is not None else []\n",
    "        self.valid_losses = valid_losses if valid_losses is not None else []\n",
    "        self.l1 = l1\n",
    "\n",
    "        logger('Model: \\n%s' % model)\n",
    "        logger('Parameters: %i' %\n",
    "               sum(param.numel() for param in model.parameters()))\n",
    "\n",
    "    def l1_penalty(self, arr):\n",
    "        return torch.abs(arr).sum()\n",
    "        \n",
    "    def training_step(self, inputs, targets):\n",
    "        '''\n",
    "        Applies single optimization step on batch\n",
    "        '''\n",
    "        \n",
    "        # define data attribiutes\n",
    "        batch_input_np = np.array(inputs[0])\n",
    "        batch_target_np = np.array(targets[0])\n",
    "        print(\"target shape: \")\n",
    "        print(batch_target_np.shape)\n",
    "        batch_input_tensor = torch.from_numpy(batch_input_np)\n",
    "        batch_target_tensor = torch.from_numpy(batch_target_np)\n",
    "        \n",
    "        # kinda jank\n",
    "        batch_size = len(inputs[0])\n",
    "        num_nodes = len(inputs[0][0]) # should be 200?\n",
    "        num_features = len(inputs[0][0][0]) # should be 6\n",
    "        \n",
    "        # flatten from 3D to 2D by combining B and V dimmensions\n",
    "        x_tensor = batch_input_tensor.view(-1, num_features)\n",
    "        \n",
    "        # tensor keeping track of which batch each entry is from, after flattening\n",
    "        batch_list = [i for i in range(batch_size) for j in range(num_nodes)]\n",
    "#         batch_list = [i for i in range(num_nodes) for j in range(batch_size)]\n",
    "        batch_np = np.array(batch_list)\n",
    "        batch_tensor = torch.from_numpy(batch_np)\n",
    "        \n",
    "        # cartesian coordinate tensor from x_tensor\n",
    "        pos_tensor = x_tensor.narrow(1,1,3)\n",
    "\n",
    "        # put data into a batch structure\n",
    "        data = Batch(batch=batch_tensor, x=x_tensor, edge_index=None, edge_attr=None, pos=pos_tensor)\n",
    "        \n",
    "#         # modify data attributes - zero-suppressed\n",
    "#         # mask based on energy - keep only sensors/cells with nonzero energy hit\n",
    "#         mask = (data.x[:,0] > 0.).squeeze()\n",
    "# #         data.x = torch.cat([data.x, data.pos], dim=-1)\n",
    "#         data.x = data.x[mask]\n",
    "#         data.pos = data.pos[mask,:]\n",
    "#         data.batch = data.batch[mask.squeeze()]\n",
    "        \n",
    "        \n",
    "        print(\"Applying single optimization step on batch\")\n",
    "        self.model.zero_grad()\n",
    "        self.optimizer.zero_grad()\n",
    "        \n",
    "        # call the forward step of our model\n",
    "        outputs = self.model(data)\n",
    "        \n",
    "#         outputs_np = np.expand_dims(outputs.detach().numpy(), axis=0)\n",
    "        outputs_np = outputs.detach().numpy()\n",
    "        print(\"outputs: \")\n",
    "        print(outputs.size())\n",
    "    \n",
    "        print(\"targets: \")\n",
    "#         print(targets)\n",
    "        print(batch_target_tensor.size())\n",
    "        \n",
    "#         # negative log likelihood loss\n",
    "#         loss = F.nll_loss(outputs, batch_target_tensor)\n",
    "\n",
    "#         loss = particle_condensation_loss(batch_target_np, outputs_np)\n",
    "    \n",
    "#         print(loss)\n",
    "        \n",
    "#         loss.backward()\n",
    "\n",
    "        #print(torch.unique(torch.argmax(result, dim=-1)))\n",
    "        #print(torch.unique(data.y))\n",
    "        self.optimizer.step()\n",
    "\n",
    "#         scheduler.batch_step()\n",
    "        \n",
    "        return loss\n",
    "\n",
    "    def save_checkpoint(self, state, is_best, filename='checkpoint.pt'):\n",
    "        directory = os.path.dirname(filename)\n",
    "        try:\n",
    "            os.stat(directory)\n",
    "        except:\n",
    "            os.mkdir(directory)\n",
    "        torch.save(state, filename)\n",
    "        if is_best:\n",
    "            bestfilename = directory+'/model_best.pt'\n",
    "            shutil.copyfile(filename, bestfilename)\n",
    "            \n",
    "    def load_checkpoint(self, filename='checkpoint.pt'):\n",
    "        checkpoint = torch.load(filename)\n",
    "        self.model.load_state_dict(checkpoint['state_dict'])\n",
    "        self.optimizer.load_state_dict(checkpoint['optimizer'])\n",
    "        self.valid_losses = checkpoint['valid_losses']\n",
    "        self.train_losses = checkpoint['train_losses']\n",
    "        \n",
    "    def load_weights(self, filename='checkpoint.pt'):\n",
    "        checkpoint = torch.load(filename)\n",
    "        old_model = copy.deepcopy(self.model)\n",
    "        old_model.load_state_dict(checkpoint['state_dict'])\n",
    "\n",
    "        def set_masked_data(new_layer, old_layer):\n",
    "            if new_layer.mask_flag:\n",
    "                new_layer.weight.data = old_layer.weight.data * old_layer.mask.data\n",
    "            else:\n",
    "                new_layer.weight.data = old_layer.weight.data\n",
    "              \n",
    "        set_masked_data(self.model.edge_network.network[0], old_model.edge_network.network[0])\n",
    "        set_masked_data(self.model.edge_network.network[2], old_model.edge_network.network[2])\n",
    "        set_masked_data(self.model.node_network.network[0], old_model.node_network.network[0])\n",
    "        set_masked_data(self.model.node_network.network[2], old_model.node_network.network[2])       \n",
    "    \n",
    "    def fit_gen(self, train_generator, n_batches=1, n_epochs=1,\n",
    "                valid_generator=None, n_valid_batches=1, verbose=0, \n",
    "                filename='checkpoint.pt'):\n",
    "        \"\"\"Runs batch training for a number of specified epochs.\"\"\"\n",
    "        epoch_start = len(self.train_losses)\n",
    "        epoch_end = epoch_start + n_epochs\n",
    "        if len(self.valid_losses) > 0:\n",
    "            best_valid_loss = self.valid_losses[-1]\n",
    "        else:\n",
    "            best_valid_loss = 99999999\n",
    "        for i in range(epoch_start, epoch_end):\n",
    "            logger('Epoch %i' % i)\n",
    "            start_time = timer()\n",
    "            sum_loss = 0\n",
    "\n",
    "            # Train the model\n",
    "            print(\"training model...\")\n",
    "            self.model.train()\n",
    "            \n",
    "            print(\"computing losses for {} batches...\".format(n_batches))\n",
    "            for j in range(n_batches):\n",
    "                batch_input, batch_target = next(train_generator)\n",
    "                print(\"batch loss: \")\n",
    "                batch_loss = (self.training_step(batch_input, batch_target)\n",
    "                              .cpu().data.item())\n",
    "                sum_loss += batch_loss\n",
    "                if verbose > 0:\n",
    "                    logger('  Batch %i loss %f' % (j, batch_loss))\n",
    "            end_time = timer()\n",
    "            avg_loss = sum_loss / n_batches\n",
    "            self.train_losses.append(avg_loss)\n",
    "            logger('  training loss %.3g time %gs' %\n",
    "                   (avg_loss, (end_time - start_time)))\n",
    "\n",
    "            # TODO: adapt this to new data scheme\n",
    "            with torch.no_grad():\n",
    "                # Evaluate the model on the validation set\n",
    "                if (valid_generator is not None) and (n_valid_batches > 0):\n",
    "                    self.model.eval()\n",
    "                    valid_loss = 0\n",
    "                    for j in range(n_valid_batches):\n",
    "                        valid_input, valid_target = next(valid_generator)\n",
    "                        valid_loss += (self.loss_func(self.model(valid_input), valid_target)\n",
    "                                       .cpu().data.item())\n",
    "                    valid_loss = valid_loss / n_valid_batches\n",
    "                    self.valid_losses.append(valid_loss)\n",
    "                    logger('  validate loss %.3g' % valid_loss)\n",
    "                \n",
    "                    #Save model checkpoint - modified\n",
    "                    logger(' save checkpoint') \n",
    "                    is_best = valid_loss < best_valid_loss\n",
    "                    best_valid_loss = min(valid_loss, best_valid_loss)\n",
    "                    self.save_checkpoint({\n",
    "                        'epoch': i + 1,\n",
    "                        'state_dict': self.model.state_dict(),\n",
    "                        'best_valid_loss': best_valid_loss,\n",
    "                        'valid_losses': self.valid_losses,\n",
    "                        'train_losses': self.train_losses,\n",
    "                        'optimizer' : self.optimizer.state_dict(),\n",
    "                    }, is_best, filename=filename)\n",
    "\n",
    "    def predict(self, generator, n_batches, concat=True):\n",
    "        with torch.no_grad():  \n",
    "            self.model.eval()\n",
    "            outputs = []\n",
    "            for j in range(n_batches):\n",
    "                test_input, test_target = next(generator)\n",
    "                outputs.append(self.model(test_input))\n",
    "            if concat:\n",
    "                outputs = torch.cat(outputs)\n",
    "            return outputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pytorch Implementation: Dynamic Reduction Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 351,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import os.path as osp\n",
    "import math\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import gc\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch_geometric.transforms as T\n",
    "\n",
    "from torch.utils.checkpoint import checkpoint\n",
    "from torch_cluster import knn_graph\n",
    "\n",
    "from torch_geometric.nn import EdgeConv, NNConv\n",
    "from torch_geometric.nn.pool.edge_pool import EdgePooling\n",
    "\n",
    "from torch_geometric.utils import normalized_cut\n",
    "from torch_geometric.utils import remove_self_loops\n",
    "from torch_geometric.utils.undirected import to_undirected\n",
    "from torch_geometric.nn import (graclus, max_pool, max_pool_x,\n",
    "                                global_mean_pool, global_max_pool,\n",
    "                                global_add_pool)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 396,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DRN with some edits to make it work for object condensation and current dataset\n",
    "\n",
    "transform = T.Cartesian(cat=False)\n",
    "\n",
    "def normalized_cut_2d(edge_index, pos):\n",
    "    row, col = edge_index\n",
    "    edge_attr = torch.norm(pos[row] - pos[col], p=2, dim=1)\n",
    "    return normalized_cut(edge_index, edge_attr, num_nodes=pos.size(0))\n",
    "\n",
    "class DynamicReductionNetwork(nn.Module):\n",
    "    # This model iteratively contracts nearest neighbour graphs \n",
    "    # until there is one output node.\n",
    "    # The latent space trained to group useful features at each level\n",
    "    # of aggregration.\n",
    "    # This allows single quantities to be regressed from complex point counts\n",
    "    # in a location and orientation invariant way.\n",
    "    # One encoding layer is used to abstract away the input features.\n",
    "    def __init__(self, input_dim=5, hidden_dim=64, output_dim=1, k=16, aggr='add',\n",
    "                 norm=torch.tensor([1.,1.,1.,1.,1.,1.])):\n",
    "        super(DynamicReductionNetwork, self).__init__()\n",
    "\n",
    "        self.datanorm = nn.Parameter(norm)\n",
    "        \n",
    "        self.k = k\n",
    "        start_width = 2 * hidden_dim\n",
    "        middle_width = 3 * hidden_dim // 2\n",
    "\n",
    "        self.inputnet =  nn.Sequential(\n",
    "            nn.Linear(input_dim, hidden_dim//2),            \n",
    "            nn.ELU(),\n",
    "            nn.Linear(hidden_dim//2, hidden_dim),\n",
    "            nn.ELU(),\n",
    "            nn.Linear(hidden_dim, hidden_dim),\n",
    "            nn.ELU(),\n",
    "        )        \n",
    "        convnn1 = nn.Sequential(nn.Linear(start_width, middle_width),\n",
    "                                nn.ELU(),\n",
    "                                nn.Linear(middle_width, hidden_dim),                                             \n",
    "                                nn.ELU()\n",
    "                                )\n",
    "        convnn2 = nn.Sequential(nn.Linear(start_width, middle_width),\n",
    "                                nn.ELU(),\n",
    "                                nn.Linear(middle_width, hidden_dim),                                             \n",
    "                                nn.ELU()\n",
    "                                )                \n",
    "        \n",
    "        # The edge convolutional operator from the “Dynamic Graph CNN for Learning on Point Clouds” paper\n",
    "        self.edgeconv1 = EdgeConv(nn=convnn1, aggr=aggr)\n",
    "        self.edgeconv2 = EdgeConv(nn=convnn2, aggr=aggr)\n",
    "        \n",
    "        self.output = nn.Sequential(nn.Linear(hidden_dim, hidden_dim),\n",
    "                                    nn.ELU(),\n",
    "                                    nn.Linear(hidden_dim, hidden_dim//2),\n",
    "                                    nn.ELU(),                                    \n",
    "                                    nn.Linear(hidden_dim//2, output_dim))\n",
    "        \n",
    "        \n",
    "    def forward(self, data):\n",
    "        data.x = self.datanorm * data.x\n",
    "        data.x = self.inputnet(data.x)\n",
    "        data.edge_index = to_undirected(knn_graph(data.x, self.k, data.batch, loop=False, flow=self.edgeconv1.flow))\n",
    "        data.x = self.edgeconv1(data.x, data.edge_index)\n",
    "        \n",
    "        print(\"data x shape: \", data.x.size())\n",
    "            \n",
    "        weight = normalized_cut_2d(data.edge_index, data.x)\n",
    "        cluster = graclus(data.edge_index, weight, data.x.size(0))\n",
    "        data.edge_attr = None\n",
    "        data = max_pool(cluster, data)\n",
    "        \n",
    "        print(\"data x shape: \", data.x.size())\n",
    "        \n",
    "        data.edge_index = to_undirected(knn_graph(data.x, self.k, data.batch, loop=False, flow=self.edgeconv2.flow))\n",
    "        data.x = self.edgeconv2(data.x, data.edge_index)\n",
    "        \n",
    "        print(\"data x shape: \", data.x.size())\n",
    "                \n",
    "        weight = normalized_cut_2d(data.edge_index, data.x)\n",
    "        cluster = graclus(data.edge_index, weight, data.x.size(0))\n",
    "        x, batch = max_pool_x(cluster, data.x, data.batch)\n",
    "        \n",
    "        print(\"x shape: \", x.size())\n",
    "\n",
    "        x = global_max_pool(x, batch)\n",
    "        \n",
    "#         upsample = nn.modules.Upsample(scale_factor=2, mode=\"linear\")\n",
    "#         upsample = nn.ConvTranspose2d(16, 33, (3, 5), stride=(2, 1), padding=(4, 2))\n",
    "#         upsample(x)\n",
    "        \n",
    "        print(\"x shape: \", x.size())\n",
    "                \n",
    "        return self.output(x).squeeze(-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PyTorch Implementation: Dynamic Reduction Network with Object Condensation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 397,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clear td variable (so we don't interfere with later declarations in this notebook)\n",
    "# td.clear()\n",
    "\n",
    "train_data = DataCollection(\"../data/train_data/dataCollection.djcdc\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 398,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from estimator import Estimator\n",
    "\n",
    "# from DynamicReductionNetwork import *\n",
    "\n",
    "import sklearn.metrics\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# device = torch.device(\"cuda\" if cuda else \"cpu\")\n",
    "\n",
    "# if cuda:\n",
    "#     np_to_torch = lambda x, volatile=False, dtype=np.float32: (torch.tensor(x.astype(dtype), requires_grad=False).cuda())\n",
    "# else:\n",
    "#     np_to_torch = lambda x, volatile=False, dtype=np.float32: (torch.tensor(x.astype(dtype), requires_grad=False))\n",
    "\n",
    "# if cuda:\n",
    "#     torch_to_np = lambda x: x.cpu().numpy()\n",
    "# else:\n",
    "#     torch_to_np = lambda x: x.detach().numpy()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 399,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-05-18 17:25:00.937691 Model: \n",
      "DynamicReductionNetwork(\n",
      "  (inputnet): Sequential(\n",
      "    (0): Linear(in_features=6, out_features=10, bias=True)\n",
      "    (1): ELU(alpha=1.0)\n",
      "    (2): Linear(in_features=10, out_features=20, bias=True)\n",
      "    (3): ELU(alpha=1.0)\n",
      "    (4): Linear(in_features=20, out_features=20, bias=True)\n",
      "    (5): ELU(alpha=1.0)\n",
      "  )\n",
      "  (edgeconv1): EdgeConv(nn=Sequential(\n",
      "    (0): Linear(in_features=40, out_features=30, bias=True)\n",
      "    (1): ELU(alpha=1.0)\n",
      "    (2): Linear(in_features=30, out_features=20, bias=True)\n",
      "    (3): ELU(alpha=1.0)\n",
      "  ))\n",
      "  (edgeconv2): EdgeConv(nn=Sequential(\n",
      "    (0): Linear(in_features=40, out_features=30, bias=True)\n",
      "    (1): ELU(alpha=1.0)\n",
      "    (2): Linear(in_features=30, out_features=20, bias=True)\n",
      "    (3): ELU(alpha=1.0)\n",
      "  ))\n",
      "  (output): Sequential(\n",
      "    (0): Linear(in_features=20, out_features=20, bias=True)\n",
      "    (1): ELU(alpha=1.0)\n",
      "    (2): Linear(in_features=20, out_features=10, bias=True)\n",
      "    (3): ELU(alpha=1.0)\n",
      "    (4): Linear(in_features=10, out_features=12, bias=True)\n",
      "  )\n",
      ")\n",
      "2020-05-18 17:25:00.937870 Parameters: 5178\n",
      "2020-05-18 17:25:00.938239 Epoch 0\n",
      "training model...\n",
      "computing losses for 14956 batches...\n",
      "batch loss: \n",
      "target shape: \n",
      "(100, 200, 11)\n",
      "Applying single optimization step on batch\n",
      "data x shape:  torch.Size([20000, 20])\n",
      "data x shape:  torch.Size([10439, 20])\n",
      "data x shape:  torch.Size([10439, 20])\n",
      "x shape:  torch.Size([5438, 20])\n",
      "x shape:  torch.Size([100, 20])\n",
      "outputs: \n",
      "torch.Size([100, 12])\n",
      "targets: \n",
      "torch.Size([100, 200, 11])\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'loss' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-399-67fa2d431064>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     61\u001b[0m \u001b[0;31m#               filename='test.pt')\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m \u001b[0mestim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_gen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgenfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_batches\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mn_train_batches\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_epochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mn_epochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilename\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'checkpoint.pt'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-350-b23dde01179f>\u001b[0m in \u001b[0;36mfit_gen\u001b[0;34m(self, train_generator, n_batches, n_epochs, valid_generator, n_valid_batches, verbose, filename)\u001b[0m\n\u001b[1;32m    184\u001b[0m                 \u001b[0mbatch_input\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_target\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_generator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    185\u001b[0m                 \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"batch loss: \"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 186\u001b[0;31m                 batch_loss = (self.training_step(batch_input, batch_target)\n\u001b[0m\u001b[1;32m    187\u001b[0m                               .cpu().data.item())\n\u001b[1;32m    188\u001b[0m                 \u001b[0msum_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mbatch_loss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-350-b23dde01179f>\u001b[0m in \u001b[0;36mtraining_step\u001b[0;34m(self, inputs, targets)\u001b[0m\n\u001b[1;32m    125\u001b[0m \u001b[0;31m#         scheduler.batch_step()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    126\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 127\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    128\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    129\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0msave_checkpoint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mis_best\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilename\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'checkpoint.pt'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'loss' is not defined"
     ]
    }
   ],
   "source": [
    "# train_data = DataCollection(\"../data/train_data/example_dataCollection.djcdc\")\n",
    "\n",
    "# splits off 10% of the training dataset for validation. Can be used in the same way as train_data\n",
    "val_data = train_data.split(0.9) \n",
    "\n",
    "# Set the batch size. \n",
    "# If the data is ragged in dimension 1 (see convert options), \n",
    "# then this is the maximum number of elements per batch, which could be distributed differently\n",
    "# to individual examples. E.g., if the first example has 50 elements, the second 48, and the third 30,\n",
    "# and the batch size is set to 100, it would return the first two examples (in total 99 elements) in \n",
    "# the first batch etc. This is helpful to avoid out-of-memory errors during training\n",
    "\n",
    "train_data.setBatchSize(100)         \n",
    "    \n",
    "# prepare the generator\n",
    "train_data.invokeGenerator()\n",
    "        \n",
    "train_data.generator.shuffleFilelist()\n",
    "# train_data.generator.prepareNextEpoch()\n",
    "\n",
    "# this number can differ from epoch to epoch for ragged data!\n",
    "n_train_batches = train_data.generator.getNBatches()\n",
    "\n",
    "\n",
    "# Model config\n",
    "hidden_dim = 20\n",
    "# n_iters = 4\n",
    "n_features = 6\n",
    "n_outputs = 12\n",
    "# number of nearest neighbors?\n",
    "k = 10\n",
    "\n",
    "n_epochs = 10 #100\n",
    "# valid_frac = 0.1\n",
    "# test_frac = 0\n",
    "\n",
    "# def __init__(self, input_dim=5, hidden_dim=64, output_dim=1, k=16, aggr='add',\n",
    "model = DynamicReductionNetwork(input_dim=n_features, hidden_dim=hidden_dim, output_dim=n_outputs, k=k)\n",
    "# loss function\n",
    "loss_func = nn.BCELoss()\n",
    "# estim = Estimator(model, loss_func=loss_func, cuda=cuda, l1 = 0)\n",
    "estim = Estimator(model, loss_func=loss_func, cuda=None, l1 = 0)\n",
    "\n",
    "# training data generator\n",
    "gen = train_data.generator\n",
    "\n",
    "def genfunc():\n",
    "    while(not gen.isEmpty()):\n",
    "        d = gen.getBatch()\n",
    "        yield d.transferFeatureListToNumpy() , d.transferTruthListToNumpy()\n",
    "\n",
    "# # test batch generator output\n",
    "# batch_input, batch_target = next(genfunc())\n",
    "# print(batch_input)\n",
    "# print(batch_target)\n",
    "\n",
    "# fit estimator with data generator(s)\n",
    "# note there are more arguments: \n",
    "# estim.fit_gen(train_batcher, n_batches=n_train_batches, n_epochs=n_epochs,\n",
    "#               valid_generator=valid_batcher, n_valid_batches=n_valid_batches, \n",
    "#               filename='test.pt')\n",
    "\n",
    "estim.fit_gen(genfunc(), n_batches=n_train_batches, n_epochs=n_epochs, filename='checkpoint.pt')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the loss\n",
    "plt.figure()\n",
    "plt.plot(estim.train_losses, label='training set')\n",
    "plt.plot(estim.valid_losses, label='validation set')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "#plt.xlim(195,300)\n",
    "#plt.ylim(.06,.08)\n",
    "plt.legend(loc=0);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
